С Kafka на интервью почти всегда копают в «а что если она начнёт вести себя плохо».  
Важно показать, что ты понимаешь не только happy-path «отправили событие → получили событие», а реальные эксплуатационные риски.

Я бы мыслил в трёх плоскостях: **производители, брокер, потребители**.

---

## 1. Проблемы со стороны producer (сервиса-отправителя)

### Потеря сообщений

Причины:

- отправили без `acks=all`
    
- брокер недоступен
    
- переполнение буфера
    
- приложение упало до flush
    

Решение:

- `acks=all`
    
- idempotent producer
    
- retry с backoff
    
- мониторинг delivery errors
    

На интервью хорошо звучит:  
**«мы включали idempotent producer и acks=all для критичных топиков телеметрии»**.

---

### Дубликаты сообщений

Kafka по умолчанию _at least once_.  
При ретраях producer может отправить одно и то же событие дважды.

Последствия:

- двойной подсчёт очков
    
- двойное обновление траектории
    
- лишние записи в БД
    

Решение:

- idempotency на consumer
    
- eventId / hash
    
- upsert в БД
    
- дедупликация по ключу
    

---

## 2. Проблемы брокера Kafka

### Lag и рост очереди

Когда consumers не успевают.

Причины:

- тяжёлые SQL операции
    
- маленькое количество partition
    
- слабые инстансы
    

Последствия:

- задержка в real-time
    
- данные «стареют»
    

Решения:

- увеличение partitions
    
- горизонтальное масштабирование consumers
    
- батч-обработка
    
- разделение топиков
    

---

### Перекос партиций (partition skew)

Один partition перегружен, остальные пустые.

Причина — плохой key.  
Например key = companyId, а одна компания генерирует 80% данных.

Решение:

- составной ключ (vehicleId)
    
- random suffix
    
- больше partitions
    

Это очень сильный ответ на интервью.

---

### Падение брокеров / кластера

Что происходит:

- недоступность топиков
    
- задержки
    
- потеря лидера партиции
    

Решения:

- replication factor ≥ 3
    
- min.insync.replicas ≥ 2
    
- правильный rack-aware placement
    
- мониторинг ISR
    

---

### Диск и retention

Kafka быстро съедает диск.

Проблемы:

- диск закончился → брокер умирает
    
- слишком длинный retention
    

Решения:

- лог-ретеншн по времени и объёму
    
- отдельные топики для сырой и агрегированной телеметрии
    
- offload в ClickHouse / S3
    

---

## 3. Проблемы consumer (сервиса-получателя)

### Потеря оффсета

Если оффсет закоммитили до обработки — потеря события.

Решение:

- commit после успешной обработки
    
- manual commit
    
- transactional consumer (реже)
    

---

### Дубликаты из-за рестарта

Consumer упал → не успел закоммитить → перечитал.

Решение:

- идемпотентность
    
- upsert / unique key
    

---

### Долгая обработка сообщений

Consumer блокируется:

- сложные расчёты
    
- синхронные HTTP вызовы
    
- тяжёлые запросы в БД
    

Решения:

- worker pool
    
- батчи
    
- async pipeline
    
- разделение топиков на fast/slow
    

---

## 4. Схемы и совместимость

Очень любят этот вопрос.

Проблемы:

- новый сервис отправляет другое JSON поле
    
- старый consumer падает
    

Решения:

- Schema Registry
    
- Avro / Protobuf
    
- backward compatibility
    
- versioning событий
    

---

## 5. Порядок сообщений

Kafka гарантирует порядок **только внутри partition**.

Проблема:

- если key плохой — события одного ТС могут прийти в разном порядке.
    

Решение:

- key = vehicleId
    
- sequence number
    
- lastSeenTimestamp
    

---

## 6. Real-time деградация

Kafka не real-time в строгом смысле.  
Это _near real-time_.

Проблемы:

- всплески нагрузки
    
- GC у consumers
    
- сеть
    

Решения:

- Redis для актуального состояния
    
- Kafka только как транспорт
    
- разделение hot/cold путей
    

---

### Как коротко сказать на интервью

Хорошая формулировка звучит примерно так:

> Основные риски — дубликаты и потеря сообщений, рост consumer lag, перекос партиций из-за плохого ключа, несовместимость схем событий и проблемы с порядком. Мы решали это через idempotent producers, commit оффсетов после обработки, ключ по vehicleId для сохранения порядка, мониторинг lag и горизонтальное масштабирование consumers. Kafka использовалась как транспорт, а актуальное состояние хранилось в Redis, поэтому даже при временной деградации очереди пользователь не терял данные.

Это показывает, что ты думаешь как человек, который **эксплуатировал систему**, а не просто читал документацию.

## Дубликаты

Дубликаты в Kafka — это **нормальная ситуация**, а не «баг».  
Kafka по своей природе _at-least-once delivery_.  
Поэтому на интервью правильный посыл не «мы избегали дубликатов», а **«мы делали систему идемпотентной»**.

Есть несколько уровней, где это решается.

---

## 1. На стороне producer

### Idempotent Producer

В Kafka есть флаг:

```
enable.idempotence=true
```

Что даёт:

- брокер понимает, что это один и тот же producer
    
- не пишет один и тот же батч дважды при ретраях
    

Но:

- это защищает **только от части дублей**
    
- не спасает, если сервис реально отправил два одинаковых события
    

Поэтому одного этого мало.

---

## 2. Уровень события (самый важный)

Каждое событие должно иметь **уникальный идентификатор**:

- `eventId` (uuid)
    
- или `(vehicleId + timestamp + sequence)`
    
- или hash payload
    

Без этого дедупликация невозможна в принципе.

---

## 3. На стороне consumer (основное место решения)

### Вариант A — Дедуп в Redis

Consumer перед обработкой делает:

```
SETNX eventId
TTL 24h
```

Если ключ уже есть → игнор.

Плюсы:

- быстро
    
- подходит для real-time
    

Минусы:

- память
    
- TTL надо подбирать
    

Для телеметрии это нормальный вариант.

---

### Вариант B — Unique constraint в БД

Например в PostgreSQL:

```
UNIQUE(vehicle_id, timestamp)
```

И вставка через:

```
INSERT ... ON CONFLICT DO NOTHING
```

Плюсы:

- железобетонная гарантия
    
- не требует Redis
    

Минусы:

- нагрузка на БД
    
- хуже для high RPS
    

Хорошо для исторических данных.

---

### Вариант C — Upsert / Merge

Если событие не «операция», а «состояние»:

- не «добавить позицию»
    
- а «текущее положение = X»
    

Тогда дубликат просто перезапишет строку.

Идеально для:

- current vehicle state
    
- leaderboards
    
- кэшей
    

---

### Вариант D — Sequence Number

У устройства есть `seq`.

Consumer хранит lastSeq:

```
if newSeq <= lastSeq → ignore
```

Очень хорошо работает для телеметрии.

---

## 4. Архитектурный приём — разделение типов данных

Ты можешь красиво сказать так:

- **Состояние** → idempotent update (Redis/Postgres upsert)
    
- **История** → unique index / дедуп
    
- **События** → eventId + Redis set
    

Это звучит как зрелое решение.

---

## Как это сказать на интервью коротко

Пример сильного ответа:

> Kafka даёт at-least-once доставку, поэтому мы изначально проектировали consumers идемпотентными. У телеметрии было уникальное событие по vehicleId + timestamp, актуальное состояние обновлялось через upsert в Redis/Postgres, а исторические данные защищались уникальными индексами. Для событий использовали Redis-дедуп с TTL. Это позволяло спокойно переживать ретраи producer’ов и рестарты consumers без логических ошибок.

Ключевая мысль, которую хотят услышать:  
**ты не борешься с дублями — ты делаешь систему устойчивой к ним.**

В Kafka под «политиками» обычно имеют в виду не одну вещь, а набор настроек и подходов:

- **как отправляются сообщения**
    
- **гарантии доставки**
    
- **политики хранения**
    
- **политики ретраев**
    
- **партиционирование**
    
- **идемпотентность / дубликаты**
    
- **acks**
    
- **consumer group поведение**
    

Интервьюер обычно проверяет: понимаешь ли ты **семантику доставки и жизненный цикл сообщения**.

Разберём по слоям, как это выглядело бы в транспортном проекте.

---

## 1. Как данные отправляются (Producer настройки)

### acks

Это самое важное.

**acks=0**

- быстро
    
- можно потерять данные
    
- почти никогда не используется для телеметрии
    

**acks=1**

- брокер подтвердил запись лидеру
    
- умер лидер → можно потерять
    
- компромисс скорость/надёжность
    

**acks=all (или -1)**

- подтвердили все реплики
    
- медленнее
    
- но почти без потерь
    

Для телеметрии обычно:  
**acks=all**

---

### retries

Если брокер не ответил:

- retries=∞ или большое число
    
- иначе можно потерять пакеты
    

---

### batch.size / linger.ms

Kafka любит батчи.

Пример логики:

- linger.ms = 5–20 мс
    
- batch.size = 32–128 KB
    

Это снижает нагрузку и повышает throughput.

---

## 2. Partitioning (как распределяются сообщения)

Ключевой момент.

Для телеметрии почти всегда:

**key = vehicle_id**

Почему:

- порядок событий по одному ТС сохраняется
    
- события не прыгают между партициями
    
- можно безопасно строить траекторию
    

Если key не задать:

- round robin
    
- порядок теряется
    

---

## 3. Политики хранения (Retention Policy)

Kafka — это лог, не очередь.

Настройки:

### retention.ms

Сколько времени хранить сообщения.

Пример:

- 3 дня
    
- 7 дней
    
- 14 дней
    

Для телеметрии часто 3–7 дней.

---

### retention.bytes

Ограничение по размеру.

Например:

- 100 GB на топик
    

---

### cleanup.policy

**delete**

- старые данные удаляются
    
- стандарт для телеметрии
    

**compact**

- оставляется только последнее значение по ключу
    
- подходит для состояния (vehicle status)
    

---

## 4. Delivery Semantics (гарантии доставки)

Это один из самых любимых вопросов.

### At most once

- быстро
    
- можно потерять
    
- редко используется
    

### At least once

- гарантированно доставим
    
- но возможны дубликаты
    
- **самый частый вариант**
    

### Exactly once

- сложно
    
- медленно
    
- редко оправдано
    

В реальности:  
**At least once + идемпотентность на потребителе**

---

## 5. Idempotent Producer

Kafka умеет:

```
enable.idempotence = true
```

Это снижает риск дублей при ретраях.

Очень хорошая вещь для телеметрии.

---

## 6. Consumer Group Policy

Как читаются данные.

### auto.offset.reset

**latest**

- читаем только новые сообщения
    

**earliest**

- читаем с начала
    

Для новых сервисов обычно:  
`earliest`

---

### Commit offsets

**auto commit**

- просто
    
- риск потерь
    

**manual commit**

- надёжнее
    
- контролируешь момент подтверждения
    

Для обработки телеметрии:  
**manual commit после успешной обработки**

---

## 7. Dead Letter / Retry Policy

Если сообщение битое:

Варианты:

- отдельный retry topic
    
- DLQ (dead letter queue)
    
- логирование + skip
    

В продакшене DLQ — очень зрелый подход.

---

## 8. Сколько партиций

Это влияет на масштабирование.

Пример логики:

- 1 партиция ≈ 5–10k msg/sec
    
- 12–24 партиции на топик — норм для телеметрии
    

---

## Как это коротко сказать на интервью

Хороший ответ звучит так:

> Для телеметрии мы использовали acks=all и идемпотентный продюсер. Сообщения партиционировались по vehicleId для сохранения порядка событий. Хранили данные в Kafka 3–7 дней с cleanup policy delete. Потребители работали по схеме at-least-once с ручным commit offset после обработки. Для батчинга использовали linger и batch size, а для ошибок — retry и отдельный DLQ топик.

Это показывает:

- понимаешь гарантии доставки
    
- знаешь retention
    
- знаешь порядок событий
    
- знаешь consumer группы
    
- не путаешь Kafka с RabbitMQ
    

Для собеседования этого уровня более чем достаточно.