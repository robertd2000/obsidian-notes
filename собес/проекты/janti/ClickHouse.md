С ClickHouse в таком проекте (телеметрия, траектории, отчёты) проблемы обычно не «сломалось», а **внезапно стало медленно / дорого / нестабильно под нагрузкой**.  
И интервьюеры как раз любят этот вопрос, потому что он показывает понимаешь ли ты его природу — это не Postgres, это аналитическое колоночное хранилище со своими ловушками.

Основные реальные проблемы такие.

---

### 1. Медленные запросы из-за неправильного ORDER BY / PARTITION BY

Самая частая ошибка.

Если таблица телеметрии создана условно так:

```
ORDER BY timestamp
```

а ты делаешь запрос:

```
WHERE vehicle_id = X
```

ClickHouse читает огромный кусок таблицы.

Правильно для телеметрии:

- `PARTITION BY toYYYYMM(timestamp)`
    
- `ORDER BY (vehicle_id, timestamp)`
    

Иначе:

- сканы гигабайтов
    
- p95 отчётов улетает в секунды/десятки секунд.
    

---

### 2. Слишком много маленьких вставок

ClickHouse не любит частые мелкие INSERT.

Если ingestion пишет по одной записи:

- создаются тысячи маленьких parts
    
- растёт merge нагрузка
    
- диск начинает «кипеть»
    

Решение:

- батчи (1000–10000 строк)
    
- буферизация
    
- Kafka + materialized view
    

---

### 3. Merge Storm

Когда:

- много вставок
    
- много partitions
    
- мало ресурсов
    

ClickHouse начинает постоянно мёржить parts → CPU 100%, диск 100%, запросы тормозят.

На интервью это звучит очень зрело, если ты скажешь:

> Были проблемы с merge pressure, решали батчированием вставок и настройкой max_parts_in_total.

---

### 4. Высокое потребление диска

Телеметрия быстро растёт:

- 10k ТС × 1 точка/5 сек → миллионы строк в день
    
- через полгода терабайты
    

Проблемы:

- диск кончился
    
- merge замедлились
    
- backup стал адом
    

Решения:

- TTL (например хранить сырые точки 3–6 месяцев)
    
- агрегации
    
- отдельная таблица для «сырая телеметрия» и «агрегаты»
    

---

### 5. Память на тяжёлых отчётах

ClickHouse может съесть десятки гигабайт RAM на один GROUP BY.

Типичные симптомы:

- OOM
    
- kill запроса
    
- нестабильность ноды
    

Решения:

- LIMIT
    
- предварительные агрегаты
    
- materialized views
    
- memory limits на пользователя
    

---

### 6. Неправильные типы данных

Если timestamp хранится как String или Float — всё деградирует:

- сортировки медленные
    
- фильтры медленные
    
- индексы бесполезны
    

Правильно:

- DateTime64
    
- UInt для id
    
- LowCardinality для строковых справочников
    

---

### 7. JOIN’ы

ClickHouse умеет JOIN, но это не его сильная сторона.

Проблемы:

- тяжёлые отчёты
    
- память
    
- медленно
    

Поэтому обычно:

- денормализация
    
- обогащение до записи
    
- materialized views
    

---

### 8. Репликация и распределённые таблицы

Если есть cluster:

- lag реплик
    
- несогласованность
    
- сложность бэкапов
    
- zookeeper проблемы
    

Это уже уровень выше, но на интервью звучит сильно.

---

## Как это сформулировать коротко на интервью

Хороший зрелый ответ выглядит примерно так:

> Основные сложности были связаны не с отказами, а с производительностью. ClickHouse чувствителен к схеме таблиц и частоте вставок. Мы столкнулись с ростом количества маленьких parts и merge-нагрузкой, поэтому перешли на батчированные вставки и настроили партиционирование по месяцу и сортировку по vehicleId + timestamp. Также использовали TTL для старых данных и materialized views для тяжёлых отчётов, чтобы не перегружать память и диск.

Тут ты показываешь:

- понимаешь физику ClickHouse
    
- работал с объёмами
    
- знаешь слова _parts, merge, partition, materialized view, TTL_  
    Для интервью этого более чем достаточно.