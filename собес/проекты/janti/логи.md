Если говорить «пусть Grafana», то важно понимать: **Grafana сама логи не хранит.**  
Она только интерфейс для просмотра. Хранилище логов — отдельный компонент.  
Самая типичная связка для твоего проекта звучит так:

**Grafana + Loki + Promtail (или Fluent Bit).**

Ниже полный флоу — как будто это реально твой прод.

---

## Общая схема

```
Go сервис → stdout / файл → Promtail (агент) → Loki → Grafana
```

---

## 1. Где логи появляются

Каждый микросервис на Go пишет логи:

- в **stdout** контейнера  
    или
    
- в **файл внутри контейнера** (`/var/log/app.log`)
    

На практике почти всегда stdout, потому что Docker/K8s это удобнее обрабатывают.

Формат — JSON:

```
{
  "ts": "2026-02-10T12:01:22Z",
  "level": "error",
  "service": "telemetry-processing",
  "trace_id": "abc123",
  "device_id": 5512,
  "msg": "failed to parse packet"
}
```

---

## 2. Когда записываются логи

Логи пишутся **в момент события**, синхронно или через буфер логгера.

Типичные события:

### Ingestion сервис

- получен пакет телеметрии
    
- невалидные координаты
    
- переподключение к Kafka
    
- перегрузка очереди
    

### Processing сервис

- ошибка обогащения
    
- дубликат пакета
    
- медленный SQL запрос
    
- Kafka lag
    

### Real-time сервис

- подключение WebSocket клиента
    
- разрыв соединения
    
- превышение лимита клиентов
    

### CRM/Auth

- логин пользователя
    
- смена роли
    
- изменение тарифа
    

Важно:  
**не логируют каждый GPS-пакет**, иначе будут терабайты мусора.  
Логируются ошибки, аномалии и ключевые события.

---

## 3. Кто забирает логи

На каждой машине/ноде крутится агент:

### Promtail (в связке с Loki)

или

### Fluent Bit

Его задачи:

- читать stdout контейнеров Docker/K8s
    
- добавлять метки (labels):
    
    - service
        
    - environment
        
    - instance
        
    - company_id (иногда)
        
- отправлять в Loki по HTTP/gRPC
    

---

## 4. Где физически хранятся логи

### Loki — это само хранилище

Он хранит:

- **индексы** — кто, где, когда
    
- **чанки логов** — сами сообщения
    

Физически это может быть:

- локальный диск сервера
    
- S3-совместимое хранилище
    
- MinIO
    
- NFS
    
- облачное объектное хранилище
    

В небольшом проекте:

```
/var/lib/loki/
```

В более зрелом:

```
S3 / Object Storage
```

---

## 5. Как долго хранятся

Настраиваются retention политики:

- error — 30 дней
    
- warn — 14 дней
    
- info — 7 дней
    
- debug — 1–3 дня
    

Это важно, иначе диск забьётся быстрее, чем ClickHouse.

---

## 6. Что делает Grafana

Grafana **ничего не хранит**.  
Она просто:

- подключается к Loki как datasource
    
- даёт UI для поиска
    
- строит дашборды
    
- делает алерты
    

Примеры запросов:

- все error по telemetry-processing за 1 час
    
- все события по device_id=123
    
- все разрывы WebSocket за сутки
    

---

## 7. Дополнительно — алерты

Через Grafana Alerting:

- > 5% error логов за минуту
    
- Kafka lag > N
    
- слишком много reconnect WebSocket
    

---

## 8. Что говорить на интервью коротко

Можно формулировать так:

> Логи сервисы писали в stdout в структурированном JSON-формате.  
> Сбор осуществлялся агентом Promtail, который отправлял их в Loki.  
> Loki выступал централизованным хранилищем логов с retention-политиками, физически данные лежали на дисках/объектном хранилище.  
> Для поиска и анализа использовалась Grafana, там же настраивались алерты.  
> Логировали в основном ошибки, ключевые бизнес-события и технические аномалии, без полного логирования телеметрического потока.

Это выглядит как зрелая прод-схема и не звучит как «мы писали print в файл».