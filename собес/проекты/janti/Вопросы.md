Если говорить про **транспортный проект с телеметрией**, интервьюер почти всегда копает в одни и те же зоны. Не потому что хочет завалить, а потому что по ним видно реальный ли у тебя опыт или ты просто «слышал слова Kafka/Redis/WebSocket».

Я бы ожидал вопросы по таким блокам.

---

## 1. Данные и поток

**Откуда приходят данные и в каком формате?**  
TCP / HTTP / MQTT, JSON или бинарный протокол, размер пакета, частота отправки.

**Что происходит если устройство шлёт мусор или дубликаты?**  
Валидация, дедупликация по deviceId + timestamp / sequence.

**Что если устройство оффлайн 3 часа и потом прислало всё пачкой?**  
Очередь, батчи, обработка без real-time приоритета.

**Как обрабатывали out-of-order события?**  
Сортировка по времени, допустимое окно запаздывания.

---

## 2. Хранилища

**Почему Redis + Postgres + ClickHouse, а не что-то одно?**  
Redis — состояние и скорость, Postgres — консистентность и бизнес-данные, ClickHouse — аналитика.

**Как выглядела схема таблиц?**  
TS id, timestamp, lat/lon, speed, fuel, eventType и индексы.

**Как чистили данные?**  
TTL в Redis, retention в Kafka, партиции / архивация в Postgres / ClickHouse.

**Как решали проблему “горячих” таблиц?**  
Партиционирование по дате или компании.

---

## 3. Реальное время

**Почему WebSocket, а не SSE / polling?**  
Двусторонность, latency, нагрузка.

**Сколько соединений держали?**  
Порядок величин важен: сотни / тысячи / десятки тысяч.

**Что происходило при разрыве соединения?**  
Reconnect + повторная подписка + добор состояния из Redis.

**Как не спамили клиентов обновлениями?**  
Throttle / debounce / агрегирование.

---

## 4. Масштабирование

**Как масштабировался ingestion?**  
Партиции Kafka + горизонтальное масштабирование инстансов.

**Как масштабировался real-time сервис?**  
Stateless + Redis pub/sub или Kafka consumer.

**Где были узкие места?**  
Redis memory, Postgres индексы, Kafka lag, WebSocket fan-out.

---

## 5. Надёжность и консистентность

**Какие гарантии доставки телеметрии?**  
At-least-once + идемпотентность.

**Что если Kafka упала?**  
Буфер на ingestion, локальная очередь, retry.

**Что если Redis упал?**  
Деградация real-time, но данные остаются в Postgres.

**Были ли потери данных?**  
Нужно уметь честно сказать «минимальные и контролируемые».

---

## 6. Бизнес-логика

**Как строилась траектория?**  
Последовательность координат + фильтрация шумов + сглаживание.

**Как определяли события (заправка, превышение)?**  
Пороговые значения + временные окна.

**Как считались отчёты?**  
Агрегации, ClickHouse или батчи.

---

## 7. Нагрузка и метрики

Очень любят цифры:

- RPS ingestion
    
- p95 / p99 latency
    
- размер базы
    
- количество ТС
    
- количество событий в секунду
    
- объём Kafka топиков
    
- сколько памяти у Redis
    

Даже если цифры приблизительные — важно чтобы они были **внутренне согласованы**.

---

## 8. Архитектурные решения

**Почему микросервисы, а не монолит?**  
Масштабирование ingestion отдельно от CRM и отчётов.

**Где были границы сервисов?**  
Телеметрия / real-time / отчёты / CRM / auth.

**Что бы сделал иначе сейчас?**  
Это почти гарантированный вопрос.

---

## 9. Безопасность

**Как авторизация?**  
JWT + RBAC.

**Как изолировались компании?**  
companyId везде, фильтрация на уровне сервисов и БД.

**Можно ли было увидеть чужие машины?**  
Нет — multi-tenant логика.

---

## 10. Операционка / DevOps

**Как деплоили?**  
Docker, CI/CD.

**Как мониторили?**  
Метрики lag Kafka, Redis memory, p95 latency API.

**Алерты были? На что?**  
Lag, memory, CPU, connection count.

---

## 11. UX / Клиентская часть

**Почему карта обновлялась именно так?**  
Баланс между нагрузкой и отзывчивостью.

**Сколько данных отправляли клиенту?**  
Только последнее состояние + дельты.

---

## 12. Самый коварный вопрос

> “А какая была самая большая проблема на проекте и как вы её решили?”

Это проверка реального опыта.  
Обычно ожидают историю про:

- лаг Kafka
    
- падение Redis по памяти
    
- WebSocket шторм
    
- тяжёлый SQL
    
- дубликаты событий
    

---

Если коротко:  
интервьюер будет проверять **данные → поток → хранение → real-time → масштабирование → надёжность → цифры → ошибки → выводы**.

Если ты уверенно рассказываешь эти восемь зон — проект выглядит как реальный продакшн, а не учебная работа.