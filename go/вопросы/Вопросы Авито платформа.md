# 1.  Горутина
Отличный вопрос! Давайте разберемся подробно.

**Горутина (Goroutine)** — это легковесный поток, управляемый средой выполнения Go (Go runtime), а не операционной системой напрямую.

Проще говоря, **это функция, которая выполняется конкурентно с другими функциями в том же адресном пространстве**. Концепция очень похожа на потоки (threads), но с ключевыми отличиями.

### Ключевые характеристики горутин

1.  **Легковесность**
    *   Запуск горутины требует всего несколько килобайт памяти, и их стек может динамически расти и сжиматься.
    *   Для сравнения: поток ОС по умолчанию может занимать 1-2 МБ. Это позволяет вам запускать *десятки тысяч* горутин одновременно без особых проблем.

2.  **Управление в пространстве пользователя**
    *   Планировщик Go (scheduler), который является частью рантайма, сам управляет горутинами, а не ОС. Он работает поверх потоков ОС (обычно их количество равно количеству ядер CPU).
    *   Планировщик распределяет горутины по этим потокам и переключается между ними в моменты, когда горутина блокируется (например, ждет I/O - чтение файла, сети и т.д.) или явно уступает место (`runtime.Gosched()`).

3.  **Простой запуск**
    *   Чтобы запустить функцию как горутину, нужно просто поставить перед ее вызовом ключевое слово `go`.
    *   Не нужно работать с низкоуровневыми примитивами, как при создании потоков в других языках.

### Простой пример

```go
package main

import (
    "fmt"
    "time"
)

// Обычная функция
func say(s string) {
    for i := 0; i < 3; i++ {
        time.Sleep(100 * time.Millisecond)
        fmt.Println(s)
    }
}

func main() {
    // Запускаем функцию say в отдельной горутине
    go say("горутина") // <- вот она, магия!

    // Вызываем функцию say в главной горутине (main)
    say("главная")

    // Небольшая задержка, чтобы горутина успела выполниться до выхода из main
    time.Sleep(500 * time.Millisecond)
}
```

**Возможный вывод:**
```
главная
горутина
горутина
главная
главная
горутина
```

Вы видите, что вывод перемешан — это доказывает, что две функции (`say("главная")` и `say("горутина")`) выполнялись *конкурентно*.

### Аналогия

Представьте, что вы — шеф-повар на кухне (ваша программа — это `main`).

*   **Поток ОС** — это как нанять еще одного повара. Это дорого (память), и их не может быть много (ограничения ОС).
*   **Горутина** — это как поставить кастрюлю на плиту и пойти резать овощи, пока она закипает. Вы, один повар, делаете несколько дел "параллельно", переключаясь между ними. Вы не ждете, пока вода закипит, стоя над кастрюлей.

### Для чего используются горутины?

Горутины — идеальный инструмент для задач, где много времени тратится на ожидание (I/O-bound задачи):

*   Обработка HTTP-запросов в веб-сервере (каждый запрос обрабатывается в своей горутине).
*   Работа с базами данных.
*   Чтение и запись файлов.
*   Общение по сети (сокеты).
*   Фоновые задачи (отправка email, генерация отчетов).

### Важные моменты и связь с каналами (Channels)

1.  **main ждет горутины**: Если главная функция `main` завершится, все запущенные в ней горутины будут немедленно остановлены. Поэтому часто нужно синхронизировать их завершение.
2.  **Синхронизация и обмен данными**: Горутины выполняются в одном адресном пространстве, поэтому они имеют доступ к общей памяти. Однако прямое чтение/запись в общую память из разных горутин небезопасно. Для безопасной коммуникации и синхронизации в Go используются **каналы (channels)**.

**Пример с каналом для синхронизации:**

```go
package main

import "fmt"

func worker(done chan bool) {
    fmt.Print("работаю...")
    // ...выполняем работу
    fmt.Println("готово!")
    // Отправляем сигнал о завершении в канал
    done <- true
}

func main() {
    // Создаем канал для синхронизации
    done := make(chan bool, 1)

    // Запускаем горутину
    go worker(done)

    // Ожидаем сигнал из канала от горутины
    <-done // Главная функция заблокируется здесь, пока не придет значение.
}
```

### Итог

**Горутина** — это фундаментальный строительный блок для конкурентного программирования в Go. Это:
*   **Легковесный поток** (дешевле потоков ОС).
*   **Простой в использовании** (достаточно ключевого слова `go`).
*   **Эффективно управляемый** (планировщиком Go).
*   **Идеальный инструмент** для создания высокопроизводительных и масштабируемых concurrent-приложений.

Сочетание **горутин** (для выполнения) и **каналов** (для коммуникации) образует мощную и элегантную модель конкурентности в Go, известную как **CSP (Communicating Sequential Processes)**.

# 2. Планировщик го
Отличный вопрос! **Планировщик Go (Go Scheduler)** — это мозг конкурентности в Go, который делает горутины такими эффективными. Давайте разберем его работу подробно.

## Что такое планировщик Go?

Это часть runtime Go, которая отвечает за распределение горутин по потокам операционной системы (OS threads) и управление их выполнением. Он работает в пространстве пользователя, а не ядра ОС.

## Архитектура: Модель M:P:G

Планировщик построен вокруг трех ключевых сущностей:

### **G (Goroutine)** - Горутина
- Представляет саму горутину
- Содержит стек, состояние выполнения, указатель на функцию

### **M (Machine) - Поток ОС**
- Абстракция над потоком ядра ОС
- Именно "M" выполняет код горутин
- Связан с ядром процессора

### **P (Processor) - Процессор**
- Виртуальный процессор, ресурс для выполнения горутин
- Каждый P имеет локальную очередь горутин
- Связывает M и G

```go
// Упрощенное представление архитектуры
[P1] -> Локальная очередь: [G1, G2, G3]
     -> M1 -> Выполняет G1
     
[P2] -> Локальная очередь: [G4, G5]
     -> M2 -> Выполняет G4

[Глобальная очередь] -> [G6, G7, G8]
```

## Как работает планировщик

### 1. **Запуск горутины**
```go
func main() {
    go myFunction() // Создается G, помещается в локальную очередь P
}
```

### 2. **Распределение работы**
- Каждый P обслуживает свою локальную очередь горутин
- Если локальная очередь пуста, P "крадет" работу из других P или глобальной очереди

### 3. **Перепланирование (scheduling)**
Планировщик вмешивается в нескольких случаях:

#### **a) Системные вызовы (блокирующие)**
```go
file, err := os.Open("file.txt") // Блокирующий системный вызов
```
- Когда горутина делает блокирующий системный вызов:
  - P "отсоединяется" от текущего M
  - Создается новый M или берется из пула для выполнения других горутин
  - Когда системный вызов завершен, G возвращается в очередь

#### **b) Сетевые операции**
```go
resp, err := http.Get("https://example.com")
```
- Go использует асинхронный ввод/вывод через netpoller
- G ставится в очередь ожидания, P освобождается для других задач
- Когда данные готовы, G возвращается в очередь выполнения

#### **c) Каналы и синхронизация**
```go
data := <-ch // Ожидание данных из канала
```
- G блокируется, P переключается на другую горутину

#### **d) Явное переключение**
```go
runtime.Gosched() // Явно уступить процессорное время
```

#### **e) Вытеснение (preemption)**
- Начиная с Go 1.14, планировщик может вытеснять долго работающие горутины
- Предотвращает "голодание" других горутин

## Преимущества такой архитектуры

### **1. Эффективность**
- Переключение между горутинами дешевле, чем между потоками ОС
- Нет переключения контекста ядра

### **2. Масштабируемость**
- Можно запускать миллионы горутин
- Автоматическое использование всех ядер CPU

### **3. Интеграция с вводом/выводом**
- Netpoller эффективно обрабатывает тысячи сетевых соединений

## Практический пример

```go
package main

import (
    "fmt"
    "runtime"
    "time"
)

func worker(id int, results chan<- int) {
    fmt.Printf("Worker %d started\n", id)
    time.Sleep(time.Second) // Имитация работы
    results <- id * 2
}

func main() {
    // Показываем количество процессоров
    fmt.Printf("Количество CPU: %d\n", runtime.NumCPU())
    fmt.Printf("Количество горутин: %d\n", runtime.NumGoroutine())
    
    results := make(chan int, 10)
    
    // Запускаем 10 горутин
    for i := 0; i < 10; i++ {
        go worker(i, results)
    }
    
    fmt.Printf("После запуска горутин: %d\n", runtime.NumGoroutine())
    
    // Собираем результаты
    for i := 0; i < 10; i++ {
        result := <-results
        fmt.Printf("Результат: %d\n", result)
    }
    
    fmt.Printf("После завершения: %d\n", runtime.NumGoroutine())
}
```

## Настройка планировщика

```go
// Установка максимального количества потоков ОС
runtime.GOMAXPROCS(4)

// Показать текущий GOMAXPROCS
fmt.Println(runtime.GOMAXPROCS(0))

// Принудительно запустить сборщик мусора
runtime.GC()

// Явно уступить процессор
runtime.Gosched()
```

## Итог

**Планировщик Go** — это интеллектуальная система, которая:
- Автоматически распределяет работу по всем ядрам CPU
- Эффективно управляет тысячами горутин
- Минимизирует блокировки потоков ОС
- Обеспечивает высокую производительность I/O-bound приложений

Благодаря планировщику программист может писать простой конкурентный код, не задумываясь о сложностях низкоуровневого управления потоками.

При запуске Go-программы среда выполнения Go спрашивает машину (виртуальную или физическую) сколько потоков операционной системы может работать параллельно. Этот вопрос основывается на количестве ядер, доступных программе. Для каждого потока, который может работать параллельно, среда выполнения создает поток операционной системы (M) и прикрепляет его к структуре данных которая представляет собой логический процессор (P) внутри программы. Эти P и M представляют собой вычислительные мощности или контекст исполнения для выполнения программы Go.

Также создается начальная горутина (G) для управления выполнением инструкций на выбранном M/P. Точно так же, как M управляет выполнением инструкций на аппаратном обеспечении, G управляет выполнением инструкций на М. Это создает новый уровень абстракции над операционной системой, но переносит управление выполнением на уровень приложений.

[![](https://tour.ardanlabs.com/tour/eng/static/img/gor1.png)](https://tour.ardanlabs.com/tour/eng/static/img/gor1.png)

Поскольку планировщик Go располагается поверх планировщика операционной системы, важно иметь некоторое семантическое представление о планировщике операционной системы и ограничениях, которые он накладывает на планировщик Go и приложения.

Задача планировщика операционной системы - создавать иллюзию того, что несколько частей работы выполняются одновременно. Даже если это физически невозможно. Это требует некоторых компромиссов при проектировании планировщика. Прежде чем продолжить, важно дать определение некоторым словам.

**Работа:** Набор инструкций для выполнения в запущенном приложении. Это выполняется потоками, и приложение может иметь от 1 до многих потоков.

**Поток:** Путь выполнения, который планируется и выполняется. Потоки отвечают за выполнение инструкций на аппаратном оборудовании.

**Состояния** **Потока:** Поток может находиться в одном из трех состояний: Выполнение, Готовность к выполнению или ожидание. Выполнение означает, что поток выполняет назначенные ему инструкции на аппаратном уровне, для этого на M ставится G. Готовность к выполнению означает, что поток хочет получить время на аппаратном обеспечении для выполнения назначенных ему инструкций и находится в очереди на выполнение. Ожидание означает, что поток ждет чего-то, прежде чем сможет продолжить свою работу. Ожидающие потоки не являются заботой планировщика.

**Конкурентность:** Это означает неопределенное выполнение вне очереди. Другими словами, набор инструкций, который должен быть выполнен в указанном порядке, выполняется в другом, неопределенном порядке, но полностью. Ключевым моментом является то, что результат выполнения полного набора инструкций в любом неопределенном порядке дает один и тот же результат. Вы скажете, что работа может выполняться параллельно, когда порядок ее выполнения не имеет значения, пока вся работа завершена.

**Параллельность:** Это означает одновременное выполнение множества действий. Чтобы это стало возможным, необходима возможность физического выполнения двух или более потоков операционной системы одновременно на аппаратном обеспечении.

**Работа,** **с** **Загрузкой** **CPU:** Это работа, которая не приводит к естественному переходу потока в состояние ожидания. Вычисление чисел Фибоначчи будет считаться работой, которая загружает CPU.

**Работа** **с** *Загрузкой **I/O:** Это работа, которая заставляет поток естественным образом переходить в состояние ожидания. состояние ожидания. Получение данных с различных URL будет считаться работой, которая загружает I/O.

**Синхронизация:** Когда двум или более горутинам необходимо получить доступ к одному и тому же месту памяти они должны быть синхронизированы и выполняться по очереди. Если синхронизация не выполняется, и хотя бы одна горутина выполняет запись, то может возникнуть гонка данных. Гонки данных являются причиной повреждения данных, баги, которые трудно обнаружить.

**Оркестрация:** Когда двум или более горутинам нужно подать друг другу сигнал, с данными или без данных, требуется механика оркестрации. Если оркестрация не происходит, гарантии одновременного выполнения и завершения работы будут упущены. Это может привести к всевозможным ошибкам, связанным с повреждением данных.

# 3. Почему горутины быстрые
Отличный вопрос! **Горутины быстрые** благодаря комбинации архитектурных решений, которые работают вместе. Давайте разберем по полочкам.

## Основные причины скорости горутин

### 1. **Легковесные стеки**

**Потоки ОС:** Фиксированный стек 1-8 МБ
```go
// Поток ОС: 1MB стека сразу
// 1000 потоков = 1000 * 1MB = 1GB памяти только на стеки!
```

**Горутины:** Динамический стек 2-8 КБ начально
```go
// Горутина: начинается с 2KB
func main() {
    for i := 0; i < 100000; i++ {
        go worker(i) // 100000 * 2KB = 200MB - приемлемо!
    }
}
```
- **Стек растет/сжимается** по мере необходимости
- **Копирование стека** при росте вместо выделения новых страниц

### 2. **Планировщик в пространстве пользователя**

```go
package main

import "runtime"

func fastSwitch() {
    // Переключение происходит БЕЗ системного вызова
    // Планировщик Go сам решает когда переключаться
    ch := make(chan int)
    
    go func() {
        ch <- 42  // Точка переключения - дешевая!
    }()
    
    <-ch  // Точка переключения - дешевая!
}
```

**Преимущества:**
- **Нет системных вызовов** для переключения
- **Нет перехода в ядро** ОС
- **Минимальные накладные расходы** на сохранение контекста

### 3. **Кооперативная многозадачность с вытеснением**

```go
func cooperativeExample() {
    go func() {
        // Горутина САМА уступает управление в определенных точках:
        // - При операциях с каналами
        // - При системных вызовах  
        // - При вызове runtime.Gosched()
        // - При работе с sync пакетом
    }()
}
```

**Точки вытеснения:**
```go
ch <- data           // Отправка в канал
<-ch                 // Получение из канала
time.Sleep()         // Сон
http.Get()           // Сетевой I/O
file.Read()          // Файловый I/O  
runtime.Gosched()    // Явное переключение
mutex.Lock()         // Синхронизация
```

### 4. **Эффективная работа с I/O через netpoller**

```go
package main

import (
    "net/http"
    "time"
)

func efficientIO() {
    for i := 0; i < 10000; i++ {
        go func(id int) {
            // Вместо блокировки потока ОС:
            resp, _ := http.Get("https://api.example.com/data")
            // Горутина приостанавливается, поток ОС освобождается
            // для выполнения других горутин!
            _ = resp
        }(i)
    }
}
```

**Netpoller magic:**
- **Неблокирующий I/O** на уровне ОС
- **Горутины "спят"** пока данные не готовы
- **Потоки ОС не блокируются** - обслуживают другие горутины

### 5. **Work-stealing планировщик**

```go
// Планировщик эффективно распределяет работу:
// [P1] -> [G1, G2, G3]  // Занят
// [P2] -> []             // Свободен - "крадет" G3 у P1!
// [P3] -> [G4, G5]       // Занят
```

**Принципы work-stealing:**
- Каждый P (процессор) имеет локальную очередь
- Если у P нет работы - крадет у других P
- **Минимизирует простои** процессоров
- **Автоматическая балансировка** нагрузки

## Сравнительный бенчмарк

```go
package main

import (
    "sync"
    "testing"
    "time"
)

// Бенчмарк горутин
func BenchmarkGoroutines(b *testing.B) {
    var wg sync.WaitGroup
    for i := 0; i < b.N; i++ {
        wg.Add(1)
        go func(id int) {
            time.Sleep(1 * time.Microsecond)
            wg.Done()
        }(i)
    }
    wg.Wait()
}

// Результаты показывают: 
// 100000 операций за несколько миллисекунд
```

## Числовое сравнение

| Операция | Потоки ОС | Горутины |
|----------|-----------|----------|
| **Создание** | 10-30 µs | 0.1-0.3 µs |
| **Переключение** | 1-1.5 µs | 0.1-0.3 µs |
| **Память** | 1-8 MB | 2-8 KB |
| **Максимум** | ~10,000 | ~1,000,000 |

## Практический пример производительности

```go
package main

import (
    "fmt"
    "net/http"
    "sync"
    "time"
)

func main() {
    start := time.Now()
    var wg sync.WaitGroup
    urls := []string{
        "https://httpbin.org/delay/1",
        "https://httpbin.org/delay/1", 
        "https://httpbin.org/delay/1",
    }
    
    // Все запросы выполняются КОНКУРЕНТНО
    for _, url := range urls {
        wg.Add(1)
        go func(u string) {
            defer wg.Done()
            resp, _ := http.Get(u)
            if resp != nil {
                resp.Body.Close()
            }
            fmt.Printf("Completed: %s\n", u)
        }(url)
    }
    
    wg.Wait()
    fmt.Printf("Total time: %v (instead of ~3s)\n", time.Since(start))
    // Вывод: Total time: ~1.1s - все запросы параллельно!
}
```

## Итог: почему горутины быстрые

1. **🚀 Легковесные** - маленькие стеки, быстрая инициализация
2. **⚡ Пользовательский планировщик** - нет дорогих системных вызовов  
3. **🔄 Умное переключение** - кооперативная модель с вытеснением
4. **📡 Эффективный I/O** - netpoller не блокирует потоки ОС
5. **🎯 Work-stealing** - автоматическая балансировка нагрузки
6. **💰 Локальные очереди** - минимум конкуренции за ресурсы

**Результат:** Go может обрабатывать миллионы одновременных соединений на одном сервере, что делает его идеальным для современных высоконагруженных приложений и микросервисов.
# 4. Внутреннее устройство горутины

# 5. Отличие потока от горутины

# 6. Воровство у горутин

# 7. Локальная очередь процесса в планировщике

# 8. Глобальная очередь

# 9. Wait очередь

# 10. Очередь net pull

# 11. Рантайм го

# 12. Сборщик мусора го

# 13. За счет чего го позволяет работать с большим кол-вом сетевых соединений

# 14. Каналы

# 15. Что будет если записать в nil канал

# 16. Что будет если прочитать в nil канал

# 17. deadlock

# 18. передача из одной горутины в другую через канал

# 19. мьютексы

# 20. как реализован буфер в го каналах

# 21. атомики

# 22. wait group

# 23. интерфейсы

# 24. утинная типизация

# 25. из чего состоят интерфейс

# 26. память в го

# 27. отличие слайса от мапы

# 28. длина слайса и емкость

# 29. как меняется длина слайса

# 30. как внутри реализована мапа

# 31. эвакуация данных

# 32. сборка мусора

# 33. write барьер

# 34. тесты в го

# 35. аргументы команды go test

# 36. моки

# 37. профилирование го программ

# 38.  рекурсивной блокировки

# 39. как увеличивается cap slice ------------------------------------

# 40. сложность операций со слайс
