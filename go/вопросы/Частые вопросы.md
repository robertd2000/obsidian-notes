https://www.youtube.com/watch?v=hJ3Y_8Zhju8

# Concurrency

### Что такое горутина - сопрограммы, корутины, горутины, файберы, грин треды
Корутины (coroutines), или сопрограммы — это блоки кода, которые работают асинхронно, то есть по очереди. В нужный момент исполнение такого блока приостанавливается с сохранением всех его свойств, чтобы запустился другой код. Когда управление возвращается к первому блоку, он продолжает работу. В результате программа выполняет несколько функций одновременно.
#### Для чего нужны корутины

- Для создания асинхронных приложений, которые могут выполнять несколько действий одновременно.
- Для гибкой и удобной реализации многозадачности.
- Для большего контроля при переключении между разными задачами. Корутинами управляют разработчик и программа, а не операционная система.
- Для снижения нагрузки на аппаратные ресурсы устройства.
#### Как работают сопрограммы

Сопрограммы — это потоки исполнения кода, которые организуются поверх системных потоков. Поток исполнения кода — это последовательность операций, выполняющихся друг за другом. Она исполняется, пока не наступит момент, который задан в коде или определен разработчиком. Затем может начать выполняться часть другой последовательности операций. В системных потоках содержатся инструкции процессора, на одном его ядре могут по очереди работать разные системные потоки. Корутины работают на более высоком уровне: несколько сопрограмм могут поочередно выполнять свой код на одном системном потоке.

Для конечного пользователя работа корутин выглядит как несколько действий, которые выполняются параллельно.

Принципы работы корутин:

- Могут иметь несколько точек для входа и возврата.
- Приостанавливаются и возобновляют работу больше одного раза.
- Действуют по стратегии LIFO — последняя вызванная корутина закончится первой.

![как работают корутины](https://blog.skillfactory.ru/wp-content/uploads/2023/02/coroutine1-3919182.png)

#### Различия между корутинами и потоками

Многозадачность с использованием корутин легко перепутать с многопоточностью. Это выполнение программы в нескольких системных потоках.

Поток — составная часть процесса, который выполняется в операционной системе. Принцип похож: несколько потоков останавливаются и возобновляются, ждут друг друга, общаются. Но есть отличия.

- Потоками управляет операционная система. Переключением корутин — разработчик с помощью кода.
- Переключение потоков сложно контролировать. Корутины контролируются более гибко.
- Потоки отнимают много ресурсов процессора — ему постоянно приходится переключаться между ними. Корутины не требуют переключения контекста, поэтому код потребляет мало ресурсов.
- Потоки выполняются на аппаратном или системном уровне. Корутины — более высокоуровневое решение. Это значит, что они дальше от системы и аппаратных ресурсов, зато ближе к человеческим понятиям.
- Потоки ускоряют выполнение сложной задачи, но отнимают много ресурсов. Корутины не повышают скорость, но помогают оптимизировать нагрузку.
- Корутины выполняются в рамках одного потока или пула потоков.

![чем отличаются корутины и потоки](https://blog.skillfactory.ru/wp-content/uploads/2023/02/coroutine2-4866697.png)

Различия между корутинами и потоками

#### Преимущества использования корутин

##### Эффективность

Многозадачная программа эффективнее расходует ресурсы. Основной код не блокируется, чтобы мог выполниться вспомогательный модуль. Вместо этого они работают асинхронно.

##### Удобство для пользователя

Корутины переключаются быстро, для пользователя это выглядит как одновременное выполнение задач. Ему не приходится подолгу ждать ответа программы. Он продолжает работать с ней, пока асинхронные корутины незаметно для него выполняют дополнительные действия.
##### Снижение нагрузки на систему

Асинхронность позволяет выполнять несколько действий в рамках одного потока вместо того, чтобы множить потоки. Системе проще выполнить один поток, чем несколько. Разработчики из JetBrains прояснили это на таком примере: запустить 10 тысяч корутин одновременно — задача, с которой устройство справится. А 10 тысяч потоков — невозможное явление: компьютеру не хватит памяти.

##### Гибкость в управлении

Переключение между корутинами происходит вручную. Программист сам прописывает этот момент в коде. Поэтому управление корутинами можно контролировать, что дает разработчику больше возможностей. Нет риска, что программа переключится между блоками кода в неподходящий момент, как это бывает с менее гибкими решениями.

#### Недостатки сопрограмм

##### Сложность и высокий порог вхождения

Разобраться в работе корутин и научиться писать асинхронный код может быть сложно. Поэтому сопрограммы начинают изучать специалисты, которые уже хорошо разобрались в базовых принципах выбранного языка.

##### Узкая специализация

Корутины — высокоуровневое решение. Ускорить сложные вычисления с помощью сопрограмм не получится. В этом случае нужна многопоточность, а не асинхронность. При этом корутины подходят для снижения нагрузки на систему.

##### Отсутствие в ряде языков

Корутины трудно реализовать в языках, которые их не поддерживают. Для этого нужно использовать сторонние решения или преобразовывать код на одном языке в другой. Это усложняет разработку.

### Различия между корутинами и потоками

Корутины и потоки — это два разных способа организации параллельного и асинхронного выполнения кода. Они имеют свои сходства и отличия, которые влияют на производительность, память, сложность и надежность программ. Вот некоторые ключевые различия между корутинами и потоками:

⭐

- **Потоки** — это сущности, которые управляются операционной системой
- **Корутины** — сущности, которые управляются языком программирования или библиотекой

⭐

- **Потоки** имеют свой собственный стек памяти
- **Корутины** используют общий стек памяти

⭐

- **Потоки** переключаются между собой прерывисто (preemptively), то есть операционная система может прервать выполнение одного потока и запустить другой в любой момент
- **Корутины** переключаются между собой согласованно (cooperatively), то есть программа или язык определяет точки, в которых корутина может приостановиться и передать управление другой

⭐

- **Потоки** могут выполняться параллельно на нескольких процессорах или ядрах
- **Корутины** выполняются последовательно в рамках одного потока

⭐

- **Потоки** требуют синхронизации доступа к общим данным с помощью механизмов блокировки, таких как мьютексы (mutex) или семафоры (semaphore)
- **Корутины** не требуют блокировки данных, так как они не выполняются одновременно

⭐

И наконец — потоки требуют больше ресурсов для создания, уничтожения и переключения, чем корутины.

### Преимущества использования корутин

Применение сопрограмм имеет ряд преимуществ по сравнению с использованием потоков. Корутины:

- **Позволяют писать асинхронный код в синхронном стиле,** что упрощает чтение и понимание кода.
- **Избавляют от необходимости использовать сложные конструкции,** такие как обратные вызовы (callback), промисы (promise) или фьючерсы (future).
- **Экономят память и время,** так как они не создают свой собственный стек и не требуют переключения контекста между собой. Это позволяет запускать большое количество корутин на одном потоке без значительных потерь производительности.
- **Поддерживают структурированную параллельность (structured concurrency),** то есть они работают в рамках определенной области видимости (scope). Это помогает избежать утечек памяти и ошибок жизненного цикла, так как корутины автоматически отменяются при выходе из своей области видимости.
- **Интегрируются с многими библиотеками и фреймворками для Android,** такими как _Jetpack_, _Retrofit_ и _Room_. Это позволяет использовать сопрограммы для работы с сетью, базами данных, пользовательским интерфейсом и другими асинхронными операциями.

### Недостатки сопрограмм

- **Требуют специального синтаксиса,** такого как ключевые слова async и await, для объявления и использования сопрограмм. Такой код не может быть смешан с синхронным кодом без дополнительных преобразований.
- **Не могут выполняться параллельно на нескольких процессорах или ядрах,** так как они работают в рамках одного потока. Это означает, что корутины не могут использоваться для задач, которые требуют высокой вычислительной мощности или распределенной обработки.
- **Могут быть сложными для отладки и тестирования,** так как они могут приводить к неожиданным результатам из-за асинхронности и кооперативности. Например, корутина может быть отменена в середине выполнения или продолжить выполнение после долгого простоя. Для облегчения отладки и тестирования корутин можно использовать специальные инструменты, такие как _Coroutine Debugger_ или _TestCoroutineDispatcher_.

В заключение, мы можем сказать, что корутины — это полезный и мощный инструмент для асинхронного программирования, который позволяет писать код в синхронном стиле, экономить ресурсы и поддерживать структурированную параллельность.

### Сопрограммы
Коротко: **горутина — это лёгкий поток выполнения в Go**, реализованный в рантайме языка, а не операционной системой. Это частный случай более общего понятия **green threads / user-space threads** и по идее ближе всего к **корутинам**, но с особенностями Go.

Разложим термины по полкам.

---

### 1. Сопрограммы (coroutines)

**Сопрограмма / корутина** — общее концептуальное понятие.

Идея:  
есть несколько функций/задач, которые **кооперативно передают управление друг другу**, сохраняя своё состояние.

Характеристики:

- не обязательно параллельны
    
- обычно **кооперативная многозадачность** (yield / resume)
    
- переключение вручную или через рантайм
    
- дешёвые по ресурсам
    

Примеры:  
Python `async/await`, Lua coroutines, Kotlin coroutines.

Корутина ≠ поток.  
Это скорее **состояние + точка продолжения**.

---

### 2. Green Threads (зелёные потоки)

**Green threads** — это **потоки, управляемые не ОС, а рантаймом языка**.

Отличие от обычных OS threads:

|Критерий|OS Thread|Green Thread|
|---|---|---|
|Кто управляет|ОС|Рантайм языка|
|Стоимость создания|Дорого|Дёшево|
|Переключение|Системный вызов|Внутри процесса|
|Количество|Сотни|Десятки/сотни тысяч|

Это **более широкий термин**, чем корутины.  
Green thread может быть:

- кооперативным
    
- вытесняемым (preemptive)
    

---

### 3. Fibers (файберы)

**Fiber** — конкретная реализация green thread.

Особенности:

- очень лёгкий поток
    
- обычно **кооперативный**
    
- переключение вручную (`yield`)
    
- используется в игровых движках, Ruby, Boost C++
    

Fiber — это скорее **низкоуровневая корутина**.

---

### 4. Goroutines (горутины в Go)

**Горутина — это green thread с планировщиком и вытеснением**, встроенный в Go runtime.

Главные особенности:

#### 1. Дешёвое создание

```go
go func() {
    fmt.Println("Hello")
}()
```

Создать 100k горутин — нормально.

#### 2. Планировщик M:N

Go runtime делает:

```
N горутин → M OS threads
```

То есть:

- 100 000 горутин
    
- 8 реальных потоков ОС
    
- runtime сам распределяет задачи
    

#### 3. Preemptive scheduling

В отличие от классических корутин:

- горутины **вытесняемые**
    
- не нужно писать `yield`
    
- рантайм сам прерывает долгие задачи
    

#### 4. Стек растёт динамически

ОС поток: ~1–8 МБ стек  
Горутина: стартует с ~2 КБ

---

### 5. Сравнение понятий

| Термин       | Что это              | Параллельность | Управление           | Пример           |
| ------------ | -------------------- | -------------- | -------------------- | ---------------- |
| Coroutine    | Концепция            | Не обязательно | Кооперативное        | Python async     |
| Fiber        | Реализация coroutine | Нет            | Кооперативное        | Ruby Fiber       |
| Green Thread | Поток в user space   | Может быть     | Runtime              | Erlang processes |
| Goroutine    | Green thread в Go    | Да             | Runtime + Preemptive | Go               |

---


### Преимущества горутин
- **Очень лёгкие** — ~2 КБ памяти на старте (поток ОС ≈ 1–8 МБ).
    
- **Дешёвое создание** — можно запускать десятки/сотни тысяч.
    
- **Автопланировщик (M:N)** — Go сам распределяет их по ядрам CPU.
    
- **Вытесняемые** — рантайм сам прерывает долгие задачи, `yield` не нужен.
    
- **Динамический стек** — растёт и уменьшается по мере надобности.
    
- **Быстрое переключение** — без системных вызовов ОС.
    
- **Простой запуск** — `go func()`.
    
- **Каналы** — удобная и безопасная коммуникация между задачами.
    
- **Отличны для I/O и сетевых сервисов** — хорошо масштабируются.
### Контекст выполнения горутин (execution context)**
 **контекст выполнения (execution context)**.

Это **состояние горутины в момент переключения**, которое рантайм Go сохраняет и восстанавливает.

---

#### Что входит в контекст горутины

Когда Go переключается между горутинами, он сохраняет:

- **Program Counter (PC)** — где остановились в коде
    
- **Stack Pointer** — позиция в стеке
    
- **Стек вызовов** — локальные переменные, аргументы функций
    
- **Регистры CPU**
    
- Ссылку на структуру `G` (внутреннее представление горутины)
    

По сути: _“снимок выполнения функции”_.

---

#### Зачем это нужно

Чтобы можно было:

- остановить горутину
    
- выполнить другую
    
- потом вернуться **ровно в ту же строку кода**
    

Без потери переменных и состояния.

---

#### Чем отличается от OS thread context

##### OS Thread

- переключает ОС
    
- дорогой системный вызов
    
- много регистров и памяти
    

##### Goroutine

- переключает Go runtime
    
- быстрее и дешевле
    
- только пользовательский стек
    

---

#### Что важно

- Переключение называется **context switch**.
    
- У горутин он **user-space**, без ядра ОС.
    
- Поэтому тысячи горутин работают эффективно.
    

---

Коротко:  
**Контекст горутины — это сохранённое состояние её выполнения (стек + регистры + позиция в коде), которое позволяет рантайму ставить её на паузу и продолжать позже.**
### Контекст потока
**Контекст потока (Thread Context)** — это **полное состояние выполнения потока в момент времени**, которое ОС сохраняет при переключении между потоками.

Проще: это «снимок» того, **где поток был и что он делал**, чтобы потом продолжить с того же места.

---

#### Что входит в контекст потока

Обычно:

- **Program Counter (PC / Instruction Pointer)** — адрес следующей инструкции
    
- **Регистры CPU** — значения рабочих регистров
    
- **Stack Pointer** — указатель на стек
    
- **Стек вызовов** — локальные переменные, аргументы функций
    
- **Флаги процессора**
    
- **Thread-local storage (TLS)**
    
- Иногда состояние FPU / SIMD регистров
    

Это всё нужно сохранить, чтобы другой поток мог использовать CPU.

---

#### Context Switch (переключение контекста)

Когда ОС переключает CPU с потока A на поток B:

1. Сохраняет контекст A в память.
    
2. Загружает контекст B из памяти.
    
3. CPU продолжает выполнять B.
    

Это **дорогая операция**, потому что:

- системный вызов
    
- работа ядра ОС
    
- сохранение множества регистров
    
- возможный cache miss
    

---

#### Почему это важно

Чем больше потоков ОС:

- тем чаще context switch
    
- тем выше накладные расходы
    
- тем хуже производительность при перегрузке
    

Поэтому 10 000 OS-потоков — плохо.

---

#### Сравнение с горутинами

|Критерий|Поток ОС|Горутина|
|---|---|---|
|Кто переключает|ОС|Go runtime|
|Стоимость|Высокая|Низкая|
|Объём контекста|Большой|Маленький|
|Системный вызов|Да|Нет|
|Масштаб|Сотни/тысячи|Десятки тысяч+|

---

**Суть:**  
Контекст потока — это набор данных (регистры, стек, указатели), который позволяет ОС остановить поток и позже продолжить его выполнение без потери состояния.
### Переключение контекста (в горутине и в потоке ОС)
**Переключение контекста (Context Switch)** — это смена выполняемой задачи на CPU с сохранением её состояния и загрузкой состояния другой.

Разница между **потоком ОС** и **горутиной** — в том, **кто переключает и сколько это стоит**.

---

#### 1. Переключение контекста потока ОС

###### Кто делает

Операционная система (ядро).

###### Что сохраняется

Почти всё состояние CPU:

- регистры процессора
    
- instruction pointer (где остановились)
    
- stack pointer
    
- стек вызовов
    
- флаги процессора
    
- FPU / SIMD регистры
    
- thread-local storage
    

###### Как происходит

1. Поток A прерывается (таймер / блокировка / sys call).
    
2. Ядро сохраняет его состояние в память.
    
3. Загружает состояние потока B.
    
4. Возвращает управление CPU.
    

##### Особенности

- **Системный вызов** (переход user → kernel → user)
    
- Дорогая операция
    
- Может ломать CPU cache
    
- Миллисекунды / десятки микросекунд
    

##### Итог

Много OS-потоков ⇒ много переключений ⇒ падение производительности.

---

#### 2. Переключение контекста горутины

###### Кто делает

Go runtime (в user space).

###### Что сохраняется

Минимальный набор:

- program counter
    
- stack pointer
    
- небольшой стек горутины
    
- внутреннюю структуру `G`
    

Нет сохранения всего состояния ядра.

###### Как происходит

1. Горутина блокируется (I/O, канал, sleep) **или вытесняется рантаймом**.
    
2. Runtime кладёт её в очередь.
    
3. Берёт следующую готовую горутину.
    
4. Продолжает выполнение.
    

Без перехода в ядро ОС.

###### Особенности

- **Нет системного вызова**
    
- Быстро (наносекунды / микросекунды)
    
- Маленький стек
    
- Не рушит кэш так сильно
    
- Масштабируется на десятки тысяч задач
    

---

#### Ключевое различие

|Параметр|Поток ОС|Горутина|
|---|---|---|
|Уровень|Kernel space|User space|
|Кто управляет|Планировщик ОС|Go runtime|
|Стоимость|Высокая|Низкая|
|Объём состояния|Большой|Маленький|
|Системный вызов|Да|Нет|
|Масштаб|Сотни–тысячи|Десятки тысяч+|

---

##### Интуитивная аналогия

- **OS поток** — переключить целый поезд на другой путь.
    
- **Горутина** — пересадить пассажира между сиденьями в одном вагоне.
    

---

**Суть:**  
Переключение контекста потока ОС — тяжёлая операция ядра.  
Переключение горутины — лёгкая операция рантайма внутри процесса, поэтому Go может эффективно работать с огромным количеством параллельных задач.
### Примитивы синхронизации
https://medium.com/german-gorelkin/synchronization-primitives-go-8857747d9660
> Пакет `**sync**` содержит примитивы, которые наиболее полезны для низкоуровневой синхронизации доступа к памяти.

#### WaitGroup

> **_WaitGroup_** _—_ это отличный способ дождаться завершения набора одновременных операций.

**Запустим несколько goroutine и дождемся завершения их работы**:

```go
var wg sync.WaitGroup  
  
**wg.Add(1)**  
go func() {  
   **defer wg.Done()**  
     
   fmt.Println("1st goroutine sleeping...")  
   time.Sleep(100 * time.Millisecond)  
}()  
  
**wg.Add(1)**  
go func() {  
   **defer wg.Done()**  
  
   fmt.Println("2nd goroutine sleeping...")  
   time.Sleep(200 * time.Millisecond)  
}()  
  
**wg.Wait()**  
fmt.Println("All goroutines complete.")
```

У нас нет гарантий когда будут запущены наши goroutine. Возможна ситуация когда при вызове `**Wait**` еще не будет ни одной запущенной goroutine. По этому важно вызвать `**Add**` за пределами процедур, которые они помогают отслеживать.

**Пример неопределенного поведения:**

```go
var wg sync.WaitGroupgo func() {  
  **wg.Add(1)**  
  defer wg.Done()  
  fmt.Println("1st goroutine sleeping...")  
  time.Sleep(1)  
 }()**wg.Wait()**  
fmt.Println("All goroutines complete.")
```

#### **О WaitGroup можно думать как о concurrent-safe счетчике.**

Вызовы `**Add**` увеличивает счетчик на переданное число, а вызовы `**Done**` уменьшают счетчик на единицу. `**Wait**` блокируется пока счетчик не станет равным нулю.

Обычно `**Add**` вызывают как можно ближе к goroutine. Но иногда удобно используют `**Add**` для отслеживания группы goroutine одновременно. **Например в таких циклах:**

```go
hello := func(wg *sync.WaitGroup, id int) {  
   defer wg.Done()  
   fmt.Printf("Hello from %v!\n", id)  
}  
  
const numGreeters = 5  
var wg sync.WaitGroup  
  
**wg.Add(numGreeters)**  
for i := 0; i < numGreeters; i++ {  
   go hello(&wg, i+1)  
}  
  
wg.Wait()
```

#### Mutex and RWMutex

> **_Mutex_** означает **mutual exclusion(взаимное исключение)** и является способом защиты **critical section(критическая секция)** вашей программы.

![](https://miro.medium.com/v2/0*ckEVpTXFoTocTwnn.png)

> **_Критическая секция_** — это область вашей программы, которая требует эксклюзивного доступа к общему ресурсу. При нахождении в критической секции двух (или более) потоков возникает состояние [**race(гонки)**](https://medium.com/german-gorelkin/race-8936927dba20). Так же возможны проблемы [**взаимной блокировки(deadlock)**](https://medium.com/german-gorelkin/deadlocks-livelocks-starvation-ccd22d06f3ae).

**Mutex обеспечивает безопасный доступ к общим ресурсам.**

Простой пример счетчика:

```go
type counter struct{  
   count int  
}  
func (c *counter) Increment() {  
   c.count++  
}  
func (c *counter) Decrement() {  
   c.count--  
}
```

Напишем тест, который будет в разных goroutine увеличивать или уменьшать общее значение:

```go
**c := new(counter)**  
  
var wg sync.WaitGroup  
numLoop := 1000  
  
wg.Add(numLoop)  
for i := 0; i < numLoop; i++ {  
   go func() {  
      defer wg.Done()  
      **c.Increment()**  
   }()  
}  
  
wg.Add(numLoop)  
for i := 0; i < numLoop; i++ {  
   go func() {  
      defer wg.Done()  
      **c.Decrement()**  
   }()  
}  
  
wg.Wait()  
  
expected := 0  
assert.Equal(t, expected, c.count)
```

**Результат**:

```
**expected: 0  
actual:   52**
```

Используем **Mutex** для синхронизации доступа:

```go
type counter struct{  
   **sync.Mutex**  
   count int  
}  
func (c *counter) Increment() {  
   **c.Lock()  
   defer c.Unlock()**  
   c.count++  
}  
func (c *counter) Decrement() {  
   **c.Lock()  
   defer c.Unlock()**  
   c.count--  
}
```

Мы вызываем `Unlock` в `defer`. Это очень распространенная идиома при использовании **Mutex**, чтобы гарантировать, что вызов всегда происходит, даже при панике. Несоблюдение этого требования может привести к **deadlock** вашей программы. Хотя `defer` и несет небольшие затраты.


Критическая секция названа так, потому что она отражает узкое место в вашей программе. Вход в критическую секцию и выход из нее обходится довольно дорого, поэтому обычно люди пытаются минимизировать время, проведенное в критических секциях.

_Возможно не все процессы будут читать и записывать в общую память. В этом случае вы можете воспользоваться мьютексом другого типа._

#### RWMutex

> **_RWMutex_** концептуально то же самое, что и **Mutex**: он защищает доступ к памяти. Тем не менее, RWMutex дает вам немного больше контроля над памятью. Вы можете запросить блокировку для чтения, и в этом случае вам будет предоставлен доступ, если блокировка не удерживается для записи.

Это означает, что произвольное число читателей может удерживать блокировку читателя, пока ничто другое не удерживает блокировку писателя.

Посмотрим как это работает:

```go
func (c *counter) CountV1() int {  
   c.Lock()  
   defer c.Unlock()  
   return c.count  
}  
func (c *counter) CountV2() int {  
  ** c.RLock()  
   defer c.RUnlock()**  
   return c.count  
}
```

CountV2 не блокирует count если не было блокировок на запись_._

**Немного бенчмарков**:

```go
func BenchmarkCountV1(b *testing.B) {  
   c := new(counter)  
   var wg sync.WaitGroup  
   for i := 0; i < b.N; i++ {  
      for j := 0; j < 1000; j++ {  
         wg.Add(1)  
         go func() {  
            defer wg.Done()  
            **c.CountV1()**  
         }()  
      }  
      wg.Wait()  
   }  
}  
  
func BenchmarkCountV2(b *testing.B) {  
   c := new(counter)  
   var wg sync.WaitGroup  
   for i := 0; i < b.N; i++ {  
      for j := 0; j < 1000; j++ {  
         wg.Add(1)  
         go func() {  
            defer wg.Done()  
            **c.CountV2()**  
         }()  
      }  
      wg.Wait()  
   }  
}
```

**Результаты**:

```
enchmarkCountV1-8           **2132**            501896 ns/op  
BenchmarkCountV2-8          **3358**            306254 ns/op
```

#### Cond

![](https://miro.medium.com/v2/resize:fit:675/0*9lPQC40kQu5Jd0EQ.PNG)

> **_Условная переменная(condition variable)_** — примитив синхронизации, обеспечивающий блокирование одного или нескольких потоков до момента поступления сигнала от другого потока о выполнении некоторого условия или до истечения максимального промежутка времени ожидания.

Сигнал не несет никакой информации, кроме факта, что произошло какое-то событие. Очень часто мы хотим подождать один из этих сигналов, прежде чем продолжить выполнение. Один из наивных подходов состоит в использовании бесконечного цикла:

```go
for conditionTrue() == false {  
   time.Sleep(1 * time.Millisecond)  
}
```

Но это довольно неэффективно, и вам нужно выяснить, как долго спать: слишком долго, и вы искусственно снижаете производительность; слишком мало, и вы отнимаете слишком много процессорного времени. Было бы лучше, если бы у процесса был какой-то способ эффективно спать, пока ему не будет дан сигнал проснуться и проверить его состояние.

Такие задачи могут решать каналы или вариации [**_паттерна PubSub(Publisher-Subscriber)_**](https://medium.com/german-gorelkin/go-observer-bc95f465961b).

Но если у вас низкоуровневая библиотека, где необходим более производительный код, тогда можно использовать тип **sync.Cond**.

##### Пример

Предположим у нас есть некоторый общий ресурс в системе. Одна группа процессов может изменять его состояния, а другая группа должна реагировать на эти изменения.

```go
type message struct {  
   cond *sync.Cond  
   msg  string  
}  
  
func main() {  
   msg := message{  
      cond: sync.NewCond(&sync.Mutex{}),  
   }  
  
   **// 1**  
   for i := 1; i <= 3; i++ {  
      go func(num int) {  
         for {  
            msg.cond.L.Lock()  
            **_msg.cond.Wait()_**  
            fmt.Printf("hello, i am worker%d. text:%s\n", num, msg.msg)  
            msg.cond.L.Unlock()  
         }  
      }(i)  
   }  
  
  ** // 2**  
   scanner := bufio.NewScanner(os.Stdin)  
   fmt.Print("Enter text: ")  
   for scanner.Scan() {  
      msg.cond.L.Lock()  
      msg.msg = scanner.Text()  
      msg.cond.L.Unlock()  
  
      **_msg.cond.Broadcast()_**  
   }  
  
}
```

**Мы запустили 3 goroutine которые ждут сигнала.** Обратите внимание, что вызов `**Wait**` не просто блокирует, он приостанавливает текущую процедуру, позволяя другим процедурам запускаться.

_При входе_ `**_Wait_**` _вызывается Unlock в Locker переменной Cond, а при выходе из_ `**_Wait_**` _вызывается Lock в Locker переменной Cond. К этому нужно немного привыкнуть._

**Во второй** части мы читаем ввод из консоли и отправляем сигнал об изменении состояния.

`**Broadcast**` отправляет сигнал всем ожидающим goroutine. А метод `**Signal**` находит goroutine, которая ждала дольше всего и будет ее.

Основные **примитивы синхронизации в Go** — это инструменты для безопасной работы с общими данными между горутинами.

---

#### 1. Mutex (`sync.Mutex`)

Взаимное исключение — **только одна горутина внутри критической секции**.

```go
var mu sync.Mutex

mu.Lock()
// критическая секция
mu.Unlock()
```

Используется когда есть shared state (map, slice, счётчики).

---

#### 2. RWMutex (`sync.RWMutex`)

Mutex с разделением на **чтение / запись**.

- много читателей одновременно
    
- только один писатель
    

```go
mu.RLock()
// чтение
mu.RUnlock()

mu.Lock()
// запись
mu.Unlock()
```

Полезен при частых чтениях и редких записях.

---

#### 3. WaitGroup (`sync.WaitGroup`)

Ожидание завершения группы горутин.

```go
var wg sync.WaitGroup

wg.Add(1)
go func() {
    defer wg.Done()
}()

wg.Wait()
```

Используется для graceful shutdown или batch-задач.

---

#### 4. Channel (каналы)

Не совсем `sync`, но главный механизм синхронизации в Go.  
**Передача данных вместо shared memory.**

```go
ch := make(chan int)
go func() { ch <- 1 }()
v := <-ch
```

Могут быть:

- буферизированные
    
- небуферизированные
    
- для сигналов (`chan struct{}`)
    

---

#### 5. Once (`sync.Once`)

Гарантирует выполнение кода **ровно один раз**.

```go
var once sync.Once
once.Do(initFunc)
```

Типично для singleton / lazy init.

---

#### 6. Cond (`sync.Cond`)

Условные переменные — редкий, низкоуровневый инструмент.  
Ожидание события под mutex.

```go
cond.Wait()
cond.Signal()
cond.Broadcast()
```

Нужен редко — чаще заменяется каналами.

---

#### 7. Atomic (`sync/atomic`)

Атомарные операции без mutex.

```go
atomic.AddInt64(&counter, 1)
```

Подходит для:

- счётчиков
    
- флагов
    
- простых состояний
    

Очень быстро, но только для примитивных типов.

---

#### Краткое правило выбора

- **Передать данные** → `channel`
    
- **Общий объект** → `Mutex / RWMutex`
    
- **Подождать горутины** → `WaitGroup`
    
- **Один раз выполнить** → `Once`
    
- **Счётчик / флаг** → `atomic`
    
- **Сложные условия ожидания** → `Cond` (редко)
    

Идеология Go:

> _“Don’t communicate by sharing memory; share memory by communicating.”_

### Мьютекс - как устроен 
**Mutex в Go (`sync.Mutex`)** — это примитив взаимного исключения, который гарантирует, что **в критической секции одновременно находится только одна горутина**.

Под капотом это не просто “флаг”, а довольно умный механизм в рантайме.

---

#### Логическая модель

У мьютекса есть два состояния:

- **Unlocked (0)** — свободен
    
- **Locked (1)** — занят
    

Но реальная реализация сложнее, чтобы быть быстрой и масштабируемой.

---

#### Как устроен внутри (упрощённо)

В `sync.Mutex` есть:

- **state (int32)** — битовая маска состояния
    
- **sema (uint32)** — семофор для блокировки/пробуждения горутин
    

##### Биты state включают:

- locked
    
- woken
    
- starving
    
- waiter count
    

То есть mutex хранит:

- занят ли он
    
- есть ли ожидающие
    
- режим голодания
    
- сколько горутин ждёт
    

---

#### Lock()

###### Быстрый путь (fast path)

Если мьютекс свободен:

- атомарный CAS (`compare-and-swap`)
    
- ставим `locked = 1`
    
- заходим в критическую секцию
    

Без системных вызовов.

---

###### Медленный путь (slow path)

Если мьютекс занят:

1. Горутина попадает в очередь ожидания.
    
2. Runtime “паркует” её (она спит, не грузит CPU).
    
3. Используется семафор (`runtime_SemacquireMutex`).
    
4. При освобождении — пробуждение.
    

---

#### Unlock()

1. Сбрасывается бит `locked`.
    
2. Если есть ожидающие — будится одна горутина.
    
3. Используется `runtime_Semrelease`.
    

---

#### Два режима работы

##### 1. Normal mode

- оптимизирован под производительность
    
- возможен “обгон” (новая горутина может захватить mutex раньше старой)
    

##### 2. Starvation mode

Включается если горутина ждёт ~1мс+.

- FIFO порядок
    
- честное распределение
    
- ниже производительность, выше справедливость
    

Go автоматически переключается между режимами.

---

#### Почему он быстрый

- Атомарные операции вместо syscalls
    
- Spin-lock на короткое время (крутится в CPU)
    
- Парковка горутин вместо busy-wait
    
- Работа полностью в user-space
    

---

#### Что важно помнить

- Mutex **не реентерабельный** (нельзя Lock дважды в одной горутине).
    
- Unlock без Lock → panic.
    
- Копировать mutex нельзя.
    
- Держать лок нужно минимальное время.
    

---

**Суть:**  
Mutex в Go — это комбинация атомарных операций + очереди ожидания + семафоров рантайма, с адаптивным переключением между скоростью и справедливостью.
### Что происходит с горутиной когда вызывается Lock
Когда горутина вызывает `mutex.Lock()`, возможны **два сценария**.

---

#### 1. Мьютекс свободен (fast path)

Что происходит:

1. Горутина делает **атомарную операцию CAS** (compare-and-swap).
    
2. Ставит флаг `locked = 1`.
    
3. Сразу заходит в критическую секцию.
    

Особенности:

- Без системных вызовов.
    
- Без сна.
    
- Практически мгновенно.
    
- CPU не переключается.
    

Это самый частый и дешёвый путь.

---

#### 2. Мьютекс занят (slow path)

Если кто-то уже держит mutex:

##### Шаги

##### 1. Короткий spin

Горутина немного “крутится” в цикле (несколько итераций CPU):

- вдруг лок освободится быстро
    
- дешевле, чем сразу засыпать
    

##### 2. Постановка в очередь

Если не освободился:

- горутина добавляется в список ожидающих
    
- увеличивается счётчик waiters
    

##### 3. Парковка (сон)

Runtime **паркует горутину**:

- она снимается с CPU
    
- не потребляет процессор
    
- сохраняется её контекст
    
- используется внутренний семафор
    

Это не `sleep()`, а именно парковка в планировщике Go.

---

#### Когда вызывается `Unlock()`

1. Mutex освобождается.
    
2. Runtime будит **одну** ожидающую горутину.
    
3. Та становится runnable.
    
4. Планировщик позже даст ей CPU.
    
5. Она продолжит выполнение **после `Lock()`**.
    

Важно: она не стартует заново — продолжается с той же строки.

---

#### Итоговое состояние горутины

При занятом mutex:

- сначала **короткий активный spin**
    
- потом **переход в sleep (parked state)**
    
- затем **wakeup → runnable → running**
    

---

#### Ключевая мысль

`Lock()` не всегда блокирует поток ОС.  
Он:

- пытается захватить лок атомарно
    
- немного крутится
    
- и только потом усыпляет горутину через runtime
    

Поэтому тысячи горутин могут ждать mutex без нагрузки на CPU и без создания тысяч потоков ОС.
### Атомики
#### Атомарные операции в Golang

Теперь давайте погрузимся в то, как атомарные операции реализованы в Golang. Пакет `sync/atomic` в стандартной библиотеке Go предоставляет множество полезных функций для выполнения атомарных операций над переменными различных типов.

##### Основные функции пакета `sync/atomic`

В пакете `sync/atomic` вы найдете несколько методов, которые предназначены для работы с разными типами данных. Давайте рассмотрим основные из них:

###### 1. `atomic.Load`

Функция `Load` используется для атомарного чтения значения из переменной. Она предотвращает некорректное чтение данных из-за асинхронного изменения.

```go
var value int32 = 42

// Здесь мы атомарно читаем значение из переменной value
currentValue := atomic.LoadInt32(&value)
fmt.Println("Current Value:", currentValue)
```

В этом примере мы используем `atomic.LoadInt32`, чтобы безопасно прочитать текущее значение переменной `value`, даже если другие потоки могут его изменять одновременно.

###### 2. `atomic.Store`

Функция `Store` служит для атомарной записи значения в переменную. Это используется, чтобы гарантировать, что запись будет завершена корректно без прерываний от других потоков.

```go
var value int32

// Здесь мы атомарно записываем значение 100 в переменную value
atomic.StoreInt32(&value, 100)
fmt.Println("New Value:", value)
```

Здесь мы используем `atomic.StoreInt32`, чтобы безопасно записать новое значение в переменную `value`.

###### 3. `atomic.Add`

С помощью функции `Add` мы можем выполнить атомарное сложение, что полезно для увеличения или уменьшения значения переменной.

```go
var counter int32 = 0

// Здесь мы атомарно увеличиваем значение переменной counter на 1
atomic.AddInt32(&counter, 1)
fmt.Println("Counter:", counter)
```

В данном примере мы увеличиваем счетчик `counter` на единицу с использованием `atomic.AddInt32`, обеспечивая при этом безопасное изменение переменной.

###### 4. `atomic.CompareAndSwap`

Это одна из самых мощных функций пакета `sync/atomic`. `CompareAndSwap` позволяет вам провести так называемый "check-and-set" цикл, который безопасен для многопоточности.

```go
var value int32 = 42

// Проверяем, равно ли значение value 42 и изменяем его на 100, если да
swapped := atomic.CompareAndSwapInt32(&value, 42, 100)
fmt.Println("Was Value Swapped?:", swapped)
```

В случае успешного выполнения, функция возвращает `true`, что указывает на успешную замену значения.

#### Заключение

Как вы могли заметить, атомарные операции в Golang невероятно полезны для обеспечения безопасности и эффективности вашего кода в многопоточных приложениях. Используя пакет `sync/atomic`, вы сможете предотвратить множество потенциальных проблем, связанных с конкурентным доступом к данным. Теперь, обладая знаниями о таких функциях, как `Load`, `Store`, `Add` и `CompareAndSwap`, вы можете более уверенно подходить к решению проблем, возникающих в многопоточных системах. Используйте атомарные операции правильно, и ваш код станет более надежным и менее подверженным ошибкам.

Атомарные операции - это полезный инструмент, но для их правильного использования необходимо глубокое понимание принципов многопоточного программирования и работы с памятью. Чтобы получить все необходимые знания и навыки, рассмотрите возможность прохождения курса [Продвинутый Golang](https://purpleschool.ru/course/go-advanced?utm_source=knowledgebase&utm_medium=text&utm_campaign=Atomarnye_operacii_v_Golang). В первых 3 модулях уже доступно бесплатное содержание — начните погружаться в мир продвинутого Go прямо сегодня и станьте экспертом.
### Проблемы конкурентности
Основные **проблемы конкурентности (concurrency issues)** — это ошибки, возникающие когда несколько потоков/горутин работают с общими ресурсами одновременно.

---

#### 1. Race Condition (Состояние гонки)

Две горутины одновременно читают/пишут одни данные → результат непредсказуем.

Пример: два инкремента счётчика без mutex → потеря значения.

Симптомы:

- плавающие баги
    
- “иногда работает”
    

---

#### 2. Deadlock (Взаимная блокировка)

Горутины ждут друг друга бесконечно.

Пример:

- A держит mutex1 и ждёт mutex2
    
- B держит mutex2 и ждёт mutex1
    

Программа зависает навсегда.

---

#### 3. Livelock

Похоже на deadlock, но горутины **активны**, просто постоянно уступают друг другу и не делают полезной работы.

CPU грузится, прогресса нет.

---

#### 4. Starvation (Голодание)

Одна горутина никогда не получает ресурс:

- mutex постоянно захватывают другие
    
- задача бесконечно в очереди
    

---

#### 5. Priority Inversion

Низкоприоритетная задача держит ресурс,  
высокоприоритетная ждёт её → система тормозит.

(Актуально больше для ОС/real-time систем.)

---

#### 6. Data Inconsistency

Нарушение целостности данных:

- половина структуры обновилась, половина нет
    
- чтение “грязного” состояния
    

---

#### 7. Goroutine Leak

Горутина никогда не завершается:

- ждёт канал
    
- забыли cancel
    
- бесконечный select
    

Память и ресурсы медленно утекают.

---

#### 8. Contention (Конкуренция за ресурс)

Слишком много горутин борются за один mutex/канал → падение производительности.

---

#### Короткая суть

|Проблема|Что происходит|
|---|---|
|Race|Непредсказуемые данные|
|Deadlock|Полная остановка|
|Livelock|Движение без прогресса|
|Starvation|Кто-то вечно ждёт|
|Leak|Утечка горутин|
|Contention|Медленно из-за блокировок|

Конкурентность даёт производительность, но без синхронизации легко приводит к нестабильным и трудноуловимым багам.
### Deadlocks, Livelocks и Starvation

[Deadlocks, Livelocks и Starvation](https://medium.com/@german.gorelkin?source=post_page---byline--ccd22d06f3ae---------------------------------------)
В 1965 году Эдсгер Дейкстра сформулировал **задачу об обедающих философах**. Задача была иллюстрацией проблем синхронизации при разработке параллельных алгоритмов и техник решения этих проблем.

В задачи были рассмотренный такие проблема, как _deadlock, livelock, resource starvation_.

![](https://miro.medium.com/v2/resize:fit:350/0*F0zL159MrAdq1K3k.jpg)

Дейкстра, Эдсгер Вибе

Саму задачу и возможные решения можно посмотреть на [wiki](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BE%D0%B1_%D0%BE%D0%B1%D0%B5%D0%B4%D0%B0%D1%8E%D1%89%D0%B8%D1%85_%D1%84%D0%B8%D0%BB%D0%BE%D1%81%D0%BE%D1%84%D0%B0%D1%85).

А мы рассмотрим проблемы синхронизации в контексте современных языков программирования.

##### Deadlock

![](https://miro.medium.com/v2/resize:fit:400/0*_O8cypE2BN3gdQbm.jpg)

fatal error: all goroutines are asleep - deadlock!

###### Что такое **deadlock** и как избежать таких ошибок?

> **Deadlock или взаимная блокировка** — это ошибка, которая происходит когда процессы имеют циклическую зависимость от пары синхронизированных объектов.

Press enter or click to view image in full size

![](https://miro.medium.com/v2/resize:fit:875/0*X_lSXRAe-CFfF14B.png)

> **Deadlock** — это программа, в которой все параллельные процессы ожидают друг друга. В этом состоянии программа никогда не восстановится без вмешательства извне.

###### Пример

[play.golang](https://play.golang.org/p/TP3qyqRJV3A)

```go
func main() {  
   var wg sync.WaitGroup  
   printSum := func(v1, v2 *value) {  
      defer wg.Done()  
  
      v1.mu.Lock() // Процесс 1 блокирует А; Процесс 2 блокирует B  
      defer v1.mu.Unlock()  
  
      time.Sleep(2 * time.Second)  
  
      v2.mu.Lock() // Процесс 1 ожидает B; Процесс 2 ожидает А  
      defer v2.mu.Unlock()  
  
      fmt.Printf("sum=%v\n", v1.value+v2.value)  
   }  
   var a, b value  
   wg.Add(2)  
   go printSum(&a, &b) // Процесс 1  
   go printSum(&b, &a) // Процесс 2  
   wg.Wait()  
}  
  
type value struct {  
   mu    sync.Mutex  
   value int  
}
```


![](https://miro.medium.com/v2/resize:fit:875/0*-BumobnjzgkPWXI-.png)

Press enter or click to view image in full size

![](https://miro.medium.com/v2/resize:fit:875/1*IQEO4cXzxwjpirFaFD2kAw.png)

**_fatal error: all goroutines are asleep — deadlock!_**

_Отладка взаимных блокировок, как и других ошибок синхронизации, усложняется тем, что для их возникновения нужны специфические условия одновременного выполнения нескольких процессов._ Если бы Процесс 1 успел захватить ресурс B до Процесса 2, то ошибка не произошла бы.

Но все не так плохо, оказывается, есть несколько условий, которые должны присутствовать для возникновения взаимных блокировок, и в 1971 году **Эдгар Коффман** перечислил эти условия в своей статье [_System Deadlocks_](http://www.ccs.neu.edu/home/pjd/cs7600-s10/Tuesday_January_26_01/p67-coffman.pdf). Условия теперь известны как **условия Кофмана** и являются основой для методов, которые помогают обнаруживать, предотвращать и исправлять взаимные блокировки.

Press enter or click to view image in full size

![](https://miro.medium.com/v2/resize:fit:875/0*e2nhKJaD9PTbbZiu.jpg)

[https://www.cs.columbia.edu/~coffman/](https://www.cs.columbia.edu/~coffman/)

###### Условия Коффмана

1. _Условие взаимного исключения._ Каждый ресурс в данный момент или отдан ровно одному процессу, или доступен.
2. _Условие удержания и ожидания._ Процессы, в данный момент удерживаю­щие полученные ранее ресурсы, могут запрашивать новые ресурсы.
3. _Условие отсутствия принудительной выгрузки ресурса._ У процесса нельзя принудительным образом забрать ранее полученные ресурсы. Процесс, владеющий ими, должен сам освободить ресурсы.
4. _Условие циклического ожидания._ Должна существовать круговая последовательность из двух и более процессов, каждый из которых ждет доступа к ресурсу, удерживаемому следующим членом последовательности.

Указанные условия являются необходимыми. То есть, _если хоть одно из них не выполняется, то взаимных блокировок никогда не возникнет._ Достаточность не имеет места быть: если выполняются все четыре условия, блокировка может и не произойти, например, если в системе нет процессов, претендующих на одновременное использование одних и тех же ресурсов.

###### Диаграммы Холта (Holt).

Отслеживать возникновение _взаимных блокировок_ удобно на _диаграммах Холта (Holt)_. Диаграмма Холта представляет собой направленный граф, имеющий два типа узлов: **процессы** (показываются кружочками) и **ресурсы** (показываются квадратиками). Тот факт, что ресурс получен процессом и в данный момент занят этим процессом, указывается ребром (стрелкой) от ресурса к процессу. Ребро, направленное от процесса, к ресурсу, означает, что процесс в данный момент блокирован и находится в состоянии ожидания доступа к соответствующему ресурсу.

![](https://miro.medium.com/v2/1*gKppA2OCI2lmEWJLBIifIg.png)

###### **Критерий deadlock**.

_Deadlock имеет место быть, тогда и только тогда, когда диаграмма Холта, отражающая состояния процессов и ресурсов,_ **_содержит цикл_**_._

##### Livelock

> **Livelock**- это программы, которые активно выполняют параллельные операции, но эти операции никак не влияют на продвижение состояния программы вперед.

Ситуация, в которой два или более процессов непрерывно изменяют свои состояния в ответ на изменения в других процессах без какой-либо полезной работы. Это похоже на deadlock, но разница в том, что процессы становятся “_вежливыми_” и позволяют другим делать свою работу.

##### Get German Gorelkin’s stories in your inbox

Join Medium for free to get updates from this writer.

Subscribe

Выполнение алгоритмов поиска удаления взаимных блокировок может привести к **livelock** — взаимная блокировка образуется, сбрасывается, снова образуется, снова сбрасывается и так далее.

_Жизненный пример такой ситуации:_

> Двое встречаются лицом к лицу. Каждый из них пытается посторониться, но они не расходятся, а несколько секунд сдвигаются в одну и ту же сторону.
> 
> Вы делаете телефонный звонок, но человек на другом конце тоже пытается вам позвонить. Вы оба повесите трубку и попробуйте снова через одно и то же время, что снова создаст такую же ситуацию. Это может продолжаться вечность.

**Рассмотрим простой пример livelock**, где муж и жена пытаются поужинать, но между ними только одна ложка. Каждый из супругов слишком вежлив, и передает ложку, если другой еще не ел.

![](https://miro.medium.com/v2/resize:fit:625/0*AUurSJkiRjcurRMQ.jpg)

[play.golang](https://play.golang.org/p/eTanKiNQxgs)

Ложка у которой есть хозяин:

```go
type spoon struct {  
   owner *diner  
}  
func (s spoon) use(){  
   fmt.Printf("%s has eaten!\n", s.owner.name)  
}type diner struct{  
   name string  
   isHungry bool  
}
```

Процесс обеда. Ложка и партнер:

```go
func (d *diner) eatWith(sp *spoon, spouse *diner) {  
   for d.isHungry {  
  
      // 1  
      if sp.owner != d {  
         time.Sleep(1 * time.Second)  
         continue  
      }  
  
      // 2  
      if spouse.isHungry {  
         fmt.Printf("%s: You eat first my darling %s!\n", d.name, spouse.name)  
         sp.owner = spouse  
         continue  
      }  
  
      // 3  
      sp.use()  
      d.isHungry = false  
      fmt.Printf("%s: I'm stuffed? my darling %s!\n", d.name, spouse.name)  
      sp.owner = spouse  
   }  
}
```

Обедаем пока не утолим голод(`isHungry=false`).

1. Если ложка сейчас не у нас, то подождем
2. Если супруг(а) голодна, то уступим и передадим ложку ему/ей
3. Используем ложку и наконец-то обедаем

Поесть этим милым ==людям== не суждено. _До третьего блока выполнение не дойдет._

[_Еще один пример._](https://github.com/GermanGorelkin/go-patterns/blob/master/concurrency/problems/deadlocks-livelocks-and-starvation/livelock/main.go)

На мой взгляд, _обнаружить livelock труднее, чем deadlock_, просто потому, что может показаться, что программа работает. Она может реагировать на сигналы, потреблять ресурсы и как то менять состояния, но выйти из цикла и завершить работу уже не в состоянии.

**Livelock— это подмножество более широкого набора проблем, называемых _Starvation_.**

##### Starvation

Press enter or click to view image in full size

![](https://miro.medium.com/v2/resize:fit:875/0*0zl-3Wg_qTqHmjOI.jpeg)

> Starvation — это любая ситуация, когда параллельный процесс не может получить все ресурсы, необходимые для выполнения его работы.

При _livelock_ все параллельные процессы одинаково _“голодают”_, и никакая работа не выполняется до конца.

В более широком смысле **starvation** обычно подразумевает наличие одного или нескольких параллельных процессов, которые несправедливо мешают одному или нескольким другим параллельным процессам выполнять работу настолько эффективно, насколько это возможно.

###### Пример

У нас будет два работника. Один жадный(`_greedyWorker_`), другой вежливый(`_politeWorker_`). Обоим дается одинаковое кол-во времени на их полезную работу — спать по 3 наносекунде.

`_greedyWorker_` _жадно_ удерживает общий ресурс(`_sharedLock_`) на протяжении всего цикла работы, тогда как `_politeWorker_` пытается блокировать его только тогда, когда это необходимо.

```go
greedyWorker := func() {  
   defer wg.Done()  
  
   var count int  
   for begin := time.Now(); time.Since(begin) <= runtime; {  
      sharedLock.Lock()  
      time.Sleep(3 * time.Nanosecond)  
      sharedLock.Unlock()  
      count++  
   }  
  
   fmt.Printf("Greedy worker was able to execute %v work loops.\n", count)  
}  
  
politeWorker := func() {  
   defer wg.Done()  
  
   var count int  
   for begin := time.Now(); time.Since(begin) <= runtime; {  
      sharedLock.Lock()  
      time.Sleep(1 * time.Nanosecond)  
      sharedLock.Unlock()  
  
      sharedLock.Lock()  
      time.Sleep(1 * time.Nanosecond)  
      sharedLock.Unlock()  
  
      sharedLock.Lock()  
      time.Sleep(1 * time.Nanosecond)  
      sharedLock.Unlock()  
  
      count++  
   }  
  
   fmt.Printf("Polite worker was able to execute %v work loops.\n", count)  
}
```

**Результат их работы**:

Greedy worker was able to execute 14111 work loops.  
Polite worker was able to execute 33301 work loops.

За одно и то же время, жадный работник получил почти вдвое больше возможностей выполнять свою работу и владеть общим ресурсом.

Конечно, lock\unlock медленные и в данном примере у `politeWorker` очень неэффективный код, **_но голодания может также применяться к процессору, памяти, файловым дескрипторам, соединениям с бд, к любому ресурсу, который должен использоваться совместно._**

_Если у вас есть параллельный процесс, который настолько жаден, что препятствует эффективно работать другим параллельным процессам, то у вас большая проблема._

Код примеров [github](https://github.com/GermanGorelkin/go-patterns/tree/master/concurrency/problems/deadlocks-livelocks-and-starvation).
### Race condition и Data Race
https://medium.com/german-gorelkin/race-8936927dba20

![](https://miro.medium.com/v2/resize:fit:963/1*sOjZdGv-o7PWaRUfYRrjDQ.jpeg)

#### Race Condition и Data Race


**Race condition** и **data race** — две разные проблемы многопоточности, которые часто путают. Попробуем разобраться.

#### Race condition

Существует много формулировок определения:

> **Race condition** представляет собой класс проблем, в которых корректное поведение системы зависит от двух независимых событий, происходящих в правильном порядке, однако отсутствует механизм, для того чтобы гарантировать фактическое возникновение этих событий.
> 
> **Race condition** — ошибка проектирования многопоточной системы или приложения, при которой работа системы или приложения зависит от того, в каком порядке выполняются части кода.
> 
> **Race condition** — это нежелательная ситуация, которая возникает, когда устройство или система пытается выполнить две или более операций одновременно, но из-за природы устройства или системы, операции должны выполняться в правильной последовательности, чтобы быть выполненными правильно.
> 
> **Race condition** — это недостаток, связанный с синхронизацией или упорядочением событий, что приводит к ошибочному поведению программы.

Но мне нравиться наиболее короткое и простое:

> **Race condition** — это недостаток, возникающий, когда время или порядок событий влияют на правильность программы.

**Важно, что Race condition — это семантическая ошибка.**

В проектирование электронных схем есть похожая проблема:

> **Состязание сигналов** — явление в цифровых устройствах несоответствия работы данного устройства с заданным алгоритмом работы по причине возникновения переходных процессов в реальной аппаратуре.

Рассмотрим пример, где результат не определен:

```go
go func() {  
   fmt.Printf("A->")  
}()  
  
go func() {  
   fmt.Printf("B")  
}()
```

Если запустить такой код много раз, то можно увидеть примерно такое:

```
A->B  
A->B  
A->B  
A->B  
BA->  
A->B
```

Результат выполнения кода зависит от порядка выполнения горутин. Это типичная ошибка race condition. Ситуации могут быть гораздо сложней и не очевидней.

**Учитывая, что race condition семантическая ошибка, нет общего способа который может отличить правильное и неправильное поведение программы в общем случае.**

Помочь могут хорошие практики и проверенные паттерны.

Еще один пример:

```go
x := 0  
for {   
	go func() {  
      x++  
   }()   
   
   go func() {  
      if x%2 == 0 {  
         time.Sleep(1 * time.Millisecond)  
         fmt.Println(x)  
      }  
   }()  
}
```

В результате на консоле получим четные и нечетные числа, а расчитывали увидеть только четные.

Проблемы с доступом к общим ресурсам проще обнаружить автоматически и решаются они обычно с помощью **синхронизации**:

```go

var mu sync.Mutex  
x := 0  
for{  
   go func() {  
      mu.Lock()  
      x++  
      mu.Unlock()  
   }()  
   go func() {  
      mu.Lock()  
      if x%2 == 0 {  
         time.Sleep(1 * time.Millisecond)  
         fmt.Println(x)  
      }  
      mu.Unlock()  
   }()  
}
```

или **локальной копией**:

```go
x := 0  
for i := 0; i < 1000; i++ {  
   go func() {  
      x++  
   }()  
   go func() {  
      y := x  
      if y%2 == 0 {  
         time.Sleep(1 * time.Millisecond)  
         fmt.Println(y)  
      }  
   }()  
}
```

#### Data Race

> **Data race** это состояние когда разные потоки обращаются к одной ячейке памяти без какой-либо синхронизации и как минимум один из потоков осуществляет запись.

Пример с балансом на счету:

```go
type account struct {  
   balance int  
}  
func deposit(acc *account, amount int) {  
   acc.balance += amount  
}
```

Запускаем в разных горутинах:

```go
acc := account{balance: 0}  
var wg sync.WaitGroup  
  
for i := 0; i < 1000; i++ {  
   wg.Add(1)  
   go func(n int) {  
      deposit(&acc, 1)  
      wg.Done()  
   }(i)  
}  
wg.Wait()  
  
fmt.Printf("balance=%d\n", acc.balance)
```

Изначально баланс равен 0, депозитим 1000 раз по 1. Ожидаем баланс равный 1000, но результат другой:

balance=**876**

Потеряли много денег.

#### Get German Gorelkin’s stories in your inbox

Join Medium for free to get updates from this writer.

Subscribe

**Причина в том, что операция** `**acc.balance += amount**` **не атомарная. Она может разложиться на 3**:

```go
tmp := acc.balance  
tmp = tmp + amount  
acc.balance = tmp
```

Пока мы меняем временную переменную в одном потоке, в других уже изменен основной balance. Таким образом теряется часть изменений.

Например, у нас 2 параллельных потока выполнения, каждый должен прибавить к балансу по 1:

```go
tmp := acc.balance // 100      ||  tmp := acc.balance // 100  
tmp = tmp + amount // 101      ||  tmp = tmp + amount // 101  
acc.balance = tmp  // 101      ||  acc.balance = tmp  // 101
```

Ожидали получить баланс=102, а получили = 101.

У **Data Race** есть точное определение, которое не обязательно связано с корректностью, и поэтому их можно обнаружить. Существует множество разновидностей детекторов гонки данных (статическое/динамическое обнаружение, обнаружение на основе блокировок, обнаружение основанное на предшествующих событий, обнаружение гибридного data race).

У Go есть хороший [**Data Race Detector**](https://golang.org/doc/articles/race_detector.html) с помощью которого такие ошибки можно обнаружить.

Решается проблема с помощью синхронизации:

```go
var mu sync.Mutex  
  
func deposit(acc *account, amount int) {  
   **mu.Lock()**  
   acc.balance += amount  
   **mu.Unlock()**  
}
```

Иногда более эффективным решением будет использовать пакет `atomic`.

```go
func deposit(acc *account, amount int64) {  
   **atomic.AddInt64**(&acc.balance, amount)  
}
```

#### Race Condition и Data Race

![](https://miro.medium.com/v2/resize:fit:890/1*yFkT-JJJTk9oRAipczlj8g.jpeg)

Функция для перевода средств с одного счета на другой:

```go
func transfer1(accFrom, accTo *account, amount int) error {  
   if accFrom.balance < amount {  
      return fmt.Errorf("accFrom.balance<amount")  
   }  
   accTo.balance += amount  
   accFrom.balance -= amount  
   return nil  
}
```

На одном счету у нас будет 1000, а на другом 0. Переводим по 1 в 1000 горутинах и ожидаем, что все деньги из одного счета перетекут в другой:

```go
accFrom := account{balance: 1000}  
accTo := account{balance: 0}  
var wg sync.WaitGroup  
  
for i := 0; i < 1000; i++ {  
   wg.Add(1)  
   go func(n int) {  
      err := transfer1(&accFrom, &accTo, 1)  
      if err != nil {  
         fmt.Printf("error for n=%d\n", n)  
      }  
      wg.Done()  
   }(i)  
}  
wg.Wait()  
  
fmt.Printf("accFrom.balance=%d\naccTo.balance=%d\n", accFrom.balance, accTo.balance)
```

Но результат может быть таким:

```go
accFrom.balance=84  
accTo.balance=915
```


Если запустить цикл на большее кол-во операций, то можно получить еще интересней:

```go
accFrom.balance=0  
accTo.balance=997
```

При вызове из нескольких потоков без внешней синхронизации эта функция допускает как **dara race** (несколько потоков могут одновременно пытаться обновить баланс счета), так и **race condition** (в параллельном контексте это приведет к потере денег).

Для решения можно применить синхронизацию и локальную копию. Общая логика может быть не такой линейной и в итоге код может выглядит например так:

```go
func transfer2(accFrom, accTo *account, amount int) error {  
   mu.Lock()  
   bal := accFrom.balance  
   mu.Unlock() 
  
   if bal < amount {  
      return fmt.Errorf("accFrom.balance<amount")  
   }   
   
	mu.Lock()  
	accTo.balance += amount  
	mu.Unlock()  
 
   mu.Lock()  
   accFrom.balance -= amount  
   mu.Unlock()  
  
   return nil  
}
```

У нас синхронизированы все участки с записью и чтением, у нас есть локальная копия, **Race Detector больше не ругается на код**. Запускаем 1000 операций и получаем верный результат:

```go
accFrom.balance=0  
accTo.balance=1000
```

Но что если горутин будет 10к:

```go
accFrom.balance=-15  
accTo.balance=1015
```

Мы решили проблему data race, но race condition остался. В данном случае можно сделать блокировку на всю логику перевода средств, но это не всегда возможно.

**Решив Data Race через синхронизацию доступа к памяти (блокировки) не всегда решается race condition и logical correctness.**

Код примеров [github](https://github.com/GermanGorelkin/go-patterns/tree/master/concurrency/problems/race).

На сегодня все. Спасибо!

#### Дополнительная информация

1. [https://blog.regehr.org/archives/490](https://blog.regehr.org/archives/490)
2. [https://dzone.com/articles/race-condition-vs-data-race](https://dzone.com/articles/race-condition-vs-data-race)
3. [https://golang.org/doc/articles/race_detector.html](https://golang.org/doc/articles/race_detector.html)
4. [https://en.wikipedia.org/wiki/Race_condition](https://en.wikipedia.org/wiki/Race_condition)



### Goroutine Leaks
https://medium.com/german-gorelkin/goroutine-leaks-bcf3bbb59997
**Горутины(goroutines) легко и быстро создавать**. К тому же они достаточно легковесные.

Рантайм мультиплексирует горутины на потоки операционной системы, занимается их запуском и переключением. Поэтому нам не приходится беспокоиться об этом уровне абстракции. Это одно из главных преимуществ Golang.

А вот управлять горутинами не так легко. Нет механизма завершения горутин из вне. Она или закончит свою работу или в ней произойдет ошибка.

Программа может создать огромное кол-во горутин которые не смогут завершить свою работу. У _garbage collector_ не будет возможности освободить занятую ими память. И это может станет проблемой.

#### Рассмотрим несколько примером Goroutine Leaks.

Особенность `nil` канала в том, что он блокирует отправителя. Подробней можно прочитать в [_Безопасная работа с каналами в Go_](https://medium.com/german-gorelkin/data-protected-by-confinement-ec6b7be401ea)_._
```go
doWork := func(strings <-chan string) <-chan interface{} {  
   completed := make(chan interface{})  
  
   go func() {  
      defer fmt.Println("doWork exited.")  
      defer close(completed)  
  
      for s := range strings {  
         fmt.Println(s)  
      }  
   }()  
   return completed  
}  
  
doWork(nil)  
  
fmt.Println("Done.")
```

**Горутина останется запущенной и будет занимать память до завершения всего процесса.**


Таких горутин может быть очень много:

```go
chans :=make([]chan string, 1_000_000)  
for _, ch := range chans{  
   // doWork(nil)  
   doWork(ch)  
}
```

##### **Возможна обратная ситуация**

Горутина блокируется при записи в канал.

```go
newZeroStream := func() <-chan int {  
   out := make(chan int)  
   go func() {  
      defer close(out)  
  
      for {  
         out <- 0  
      }  
   }()  
   return out  
}  
  
ch := newZeroStream()  
fmt.Println("3 zeros:")  
for i := 1; i <= 3; i++ {  
   fmt.Printf("%d: %d\n", i, <-ch)  
}
```

Мы прочитали нужные нам три нолика и пошли дальше. А newZeroStream осталась заблокирована навсегда.

_Точно так же горутины могут утекать в ожидании данных из сети, от пользователя, от других подсистем и прочие._

#### Родительский контроль

![](https://miro.medium.com/v2/resize:fit:704/0*s7gedd8tPw8QCl1b)

Для решения таких проблем нам нужна связь между родительской программой и дочерними горутинами.

**Родительская горутина должна иметь возможность сигнализировать об отмене своим подопечным. А дочерние элементы должны обрабатывать такие сигналы и корректно завершаться.**

По соглашению, _сигналом_ обычно является канал только для чтения с именем `**done**`. Родительская программа передает этот канал дочерней программе, а затем закрывает канал, когда нужно отменить дочернюю программу.

```go
doWork := func(done <-chan interface{}, strings <-chan string,  
) <-chan interface{} { // 1  
   terminared := make(chan interface{})  
  
   go func() {  
      defer close(terminared)  
  
      for {  
         select {  
         case <-done: // 2  
            return  
         case s := <-strings:  
            fmt.Println(s)  
         }  
      }  
   }()  
   return terminared  
}  
  
done := make(chan interface{})  
terminated := doWork(done, nil)  
  
go func() { // 3  
   // Cancel the operation after 1 second  
   time.Sleep(1 * time.Second)  
   close(done)  
}()  
  
<-terminated //4  
fmt.Println("Done.")
```

1. Передаем первым параметром сигнальный канал `**done**`
2. Используем `**for-select**` с проверкой на поступления сигнала от родительской горутины. Если сигнал поступил, то завершаем горутину.
3. Таймаут. Отдельная горутина которая отправит сигнал о завершении через 1 сек, если `doWork` еще будет работать.
4. Синхронизация с `doWork`

#### Context

В Go 1.7 появился пакет `context`. **Context** решает туже задачу что и паттерн done и даже больше. На данный момент является стандартным решение.

```go
newZeroStream := func(ctx context.Context) <-chan int {  
   out := make(chan int)  
   go func() {  
      defer close(out)  
  
      for {  
         select {  
         case <-ctx.Done():  
            return  
         case out <- 0:  
         }  
      }  
   }()  
   return out  
}  
  
ctx, cancel := context.WithCancel(context.Background())
ch := newZeroStream(ctx)  
fmt.Println("3 zeros:")  
for i := 1; i <= 3; i++ {  
   fmt.Printf("%d: %d\n", i, <-ch)  
}  
cancel()
```

![](https://miro.medium.com/v2/resize:fit:688/0*4ZAnUwQG1PyYd58r.jpg)

> **Горутина которая ответственна за создания других горутин, так же ответственна за их завершение.**

Утечка ресурсов большая и сложная тема. Сегодня мы рассмотрели один из базовых, но важных принципов работы с горутинами в Go. Он поможет писать более качественный код и решить часть проблемы.


# Планировщик Go

### Модели многозадачности
#### Кооперативная многозадачность
**Модели многозадачности** — это способы, как система распределяет выполнение нескольких задач во времени и на CPU.

Основные модели:

---

#### 1. Кооперативная (Cooperative Multitasking)

Задачи **сами уступают управление**.

Принцип:  
задача должна добровольно вызвать `yield`.

Плюсы:

- простая реализация
    
- дешёвое переключение
    

Минусы:

- одна “зависшая” задача блокирует всё
    
- нет гарантий справедливости
    

Примеры:

- старые Windows 3.x
    
- классические корутины, fibers
    

---

#### 2. Вытесняемая (Preemptive Multitasking)

Планировщик **насильно прерывает задачи** по таймеру.

Плюсы:

- система не зависает из-за одной задачи
    
- честное распределение CPU
    
- параллелизм на ядрах
    

Минусы:

- дороже переключения
    
- сложнее синхронизация
    

Примеры:

- современные ОС
    
- потоки Linux/Windows
    
- горутины Go (вытесняемые рантаймом)
    

---

#### 3. Модель потоков ОС (1:1)

Одна задача = один поток ОС.

Плюсы:

- настоящий параллелизм
    
- простая ментальная модель
    

Минусы:

- дорогие потоки
    
- плохая масштабируемость (тысячи уже тяжело)
    

---

#### 4. Green Threads / User-Space Threads (M:N)

Много задач мапятся на меньшее число потоков ОС.

Плюсы:

- лёгкие задачи
    
- быстрые переключения
    
- высокая масштабируемость
    

Минусы:

- сложный рантайм
    
- возможны блокировки при системных вызовах (если плохо реализовано)
    

Примеры:

- Go goroutines
    
- Erlang processes
    

---

#### 5. Event Loop (Reactor / Async I/O)

Один поток + очередь событий + неблокирующие операции.

Плюсы:

- минимальные накладные расходы
    
- отлично для I/O
    

Минусы:

- CPU-heavy задачи блокируют цикл
    
- сложнее писать линейную логику
    

Примеры:

- Node.js
    
- JavaScript в браузере
    
- Python asyncio
    

---

#### Короткое сравнение

| Модель      | Кто переключает | Масштаб       | Риск зависания |
| ----------- | --------------- | ------------- | -------------- |
| Cooperative | Задачи          | Высокий       | Высокий        |
| Preemptive  | Планировщик     | Высокий       | Низкий         |
| 1:1 Threads | ОС              | Средний       | Низкий         |
| M:N Green   | Runtime         | Очень высокий | Низкий         |
| Event Loop  | Цикл событий    | Очень высокий | Средний        |
|             |                 |               |                |

**Суть:**

- Потоки ОС — просто, но тяжело.
    
- Green threads / горутины — масштабируемо.
    
- Event loop — эффективно для I/O.
    
- Кооперативная — лёгкая, но опасна зависаниями.
### Вытесняющая многозадачность
Решение принимается в соответствии с приоритетами задач. В отличие от [кооперативной многозадачности](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BE%D0%BF%D0%B5%D1%80%D0%B0%D1%82%D0%B8%D0%B2%D0%BD%D0%B0%D1%8F_%D0%BC%D0%BD%D0%BE%D0%B3%D0%BE%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%BD%D0%BE%D1%81%D1%82%D1%8C "Кооперативная многозадачность"), управление операционной системе передаётся вне зависимости от состояния работающих приложений, благодаря чему, в частности, зависшие (к примеру — [зациклившиеся](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D1%86%D0%B8%D0%BA%D0%BB%D0%B8%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5 "Зацикливание")) приложения, как правило, не «подвешивают» операционную систему. За счёт регулярного переключения задач также улучшается отзывчивость системы, оперативность освобождения ресурсов системы, которые больше не используются задачей

В реализации вытесняющая многозадачность отличается от кооперативной, в частности, тем, что требует обработки системного [прерывания](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B5%D1%80%D1%8B%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5 "Прерывание") от аппаратного. По истечении кванта времени, отведённого процессу, происходит прерывание и вызывается [планировщик процессов](https://ru.wikipedia.org/wiki/%D0%9F%D0%BB%D0%B0%D0%BD%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D0%B2 "Планировщик процессов"). Частота вызова планировщика критична: слишком частый его вызов будет расходовать процессорное время впустую.
#### Вытесняющая многозадачность (Preemptive Multitasking)

**Вытесняющая многозадачность** — модель, при которой **планировщик принудительно прерывает выполняемую задачу** и передаёт CPU другой, не спрашивая разрешения текущей.

---

#### Как работает

1. Задача выполняется на CPU.
    
2. Срабатывает таймер прерывания (time slice / квант времени).
    
3. Планировщик ОС или рантайм:
    
    - сохраняет контекст текущей задачи
        
    - выбирает следующую готовую
        
    - загружает её контекст
        
4. Выполнение продолжается уже в другой задаче.
    

Задача **не может “захватить процессор навсегда”**.

---

#### Ключевые свойства

- **Принудительное переключение**
    
- **Квант времени** (обычно миллисекунды)
    
- **Справедливое распределение CPU**
    
- **Настоящий параллелизм** на многоядерных системах
    
- Требует **синхронизации** (mutex, atomic и т.п.)
    

---

#### Плюсы

- Одна зависшая задача не блокирует систему.
    
- Хорошая отзывчивость UI/сервисов.
    
- Эффективное использование многоядерных CPU.
    
- Предсказуемость распределения ресурсов.
    

---

#### Минусы

- Дорогие переключения контекста.
    
- Сложность конкурентного кода.
    
- Race condition, deadlock и др.
    
- Накладные расходы ядра ОС / рантайма.
    

---

#### Где используется

- Современные ОС (Linux, Windows, macOS).
    
- Потоки ОС (POSIX threads).
    
- Горутины Go — вытесняются рантаймом (user-space preemption).
    

---

#### Сравнение с кооперативной

|Критерий|Кооперативная|Вытесняющая|
|---|---|---|
|Кто переключает|Сама задача|Планировщик|
|Риск зависания|Высокий|Низкий|
|Контроль разработчика|Высокий|Низкий|
|Сложность синхронизации|Ниже|Выше|

**Суть:**  
CPU может быть отобран у задачи в любой момент, что повышает стабильность и отзывчивость системы, но делает конкурентный код сложнее.
### Какая многозадачность в го
В **Go используется вытесняющая многозадачность (preemptive multitasking)** на уровне **рантайма**, а не ОС.

Точнее:

> **M:N планирование + вытесняемые green threads (горутины).**

---

#### Что это значит

##### 1. Green Threads

Горутины — не потоки ОС.  
Ими управляет **Go runtime** в user-space.

---

##### 2. M:N модель

```
M горутин → N потоков ОС
```

Например:

- 100 000 горутин
    
- 8 OS threads
    
- runtime сам распределяет работу по ядрам
    

---

##### 3. Вытесняемость

Горутина **может быть прервана принудительно**, даже если она не делает `yield`.

Рантайм:

- ставит таймеры
    
- вставляет safe points
    
- может остановить долгий цикл
    

Это отличает Go от чисто кооперативных корутин.

---

##### 4. Где происходит переключение

Не в ядре ОС, а внутри процесса:

- быстрее
    
- дешевле
    
- меньше context switch overhead
    

---

#### Итоговая формулировка

**В Go — вытесняющая пользовательская многозадачность (user-space preemptive multitasking) с M:N планировщиком горутин.**

То есть:

- не кооперативная
    
- не 1:1 потоки ОС
    
- гибрид: лёгкие задачи + принудительное планирование рантаймом.
### Внутреннее устройство планировщика го
**Планировщик Go (Go Scheduler)** — это часть runtime, которая решает **какая горутина, на каком потоке ОС и на каком ядре CPU будет выполняться**.

Основан на модели **G-M-P** и алгоритме **work stealing**.

---

#### Модель G-M-P

##### G — Goroutine

Лёгкая задача.

Содержит:

- стек
    
- регистры / program counter
    
- статус (runnable / running / waiting)
    
- ссылку на функцию
    

Это “юнит работы”.

---

##### M — Machine (OS Thread)

Настоящий поток ОС.

- выполняет инструкции CPU
    
- дорогой ресурс
    
- может блокироваться на системных вызовах
    

---

##### P — Processor (логический процессор)

Ключевая сущность планировщика.

Содержит:

- **локальную очередь горутин**
    
- кэш аллокатора памяти
    
- служебные структуры рантайма
    

Количество `P` = `GOMAXPROCS` (обычно число ядер CPU).

**Без P поток M не может выполнять Go-код.**

---

#### Связи

```
G (много) → P (≈ ядра CPU) → M (OS threads) → CPU
```

- `M` берёт `P`
    
- `P` даёт `G`
    
- `M` выполняет `G` на CPU
    

---

#### Очереди горутин

##### Локальная очередь P

- основной источник задач
    
- очень быстрая (без глобальных локов)
    
- ограниченный размер (~256)
    

##### Глобальная очередь

Используется когда:

- локальная переполнена
    
- локальная пуста
    
- при создании новых горутин
    

---

#### Work Stealing

Балансировка нагрузки:

Если у `P` нет задач → он **крадёт половину очереди** у другого `P`.

Это даёт:

- равномерную загрузку ядер
    
- хорошую масштабируемость
    

---

#### Состояния горутин

- **Running** — выполняется
    
- **Runnable** — готова к запуску
    
- **Waiting** — ждёт I/O / mutex / channel
    
- **Dead** — завершена
    

---

#### Блокирующие операции

Когда горутина делает системный вызов или I/O:

1. `M` может заблокироваться.
    
2. Runtime отсоединяет `P` от этого `M`.
    
3. Другой `M` подхватывает `P`.
    
4. CPU не простаивает.
    

---

#### Netpoller (сеть)

Для сетевого I/O используется epoll/kqueue:

- горутина уходит в `waiting`
    
- поток ОС не блокируется
    
- событие сети → горутина становится `runnable`
    

---

#### Вытеснение (Preemption)

Начиная с Go 1.14 — **асинхронное вытеснение**:

- рантайм может прервать долгую горутину
    
- используются safe points и сигналы
    
- предотвращает захват CPU одной задачей
    

---

#### Почему это быстро

- M:N модель (много G на мало M)
    
- маленькие стеки горутин
    
- переключения в user-space
    
- локальные очереди без глобальных локов
    
- work stealing вместо централизованного планировщика
    

---

##### Суть в одной фразе

Планировщик Go — это **распределённая система очередей (P) и потоков ОС (M), выполняющая лёгкие задачи (G) с кражей работы и вытесняемым выполнением**, что позволяет эффективно гонять сотни тысяч горутин на ограниченном числе ядер.
### GMP модель
### Очереди (локальная, глобальная)
В планировщике Go есть **две основные очереди горутин**:

- **Локальная очередь (Local Run Queue)**
    
- **Глобальная очередь (Global Run Queue)**
    

Они нужны для быстрого и равномерного распределения задач между ядрами CPU.

---

#### Локальная очередь (Local Run Queue)

У **каждого P (Processor)** есть **своя собственная очередь горутин**.

##### Особенности

- Очень быстрая (нет глобальных локов)
    
- Небольшого размера (~256 горутин)
    
- Основной источник задач для выполнения
    
- Работает в основном как FIFO + иногда LIFO
    

##### Как используется

Когда горутина создаётся (`go func()`):

- чаще всего она кладётся в локальную очередь текущего `P`
    

Когда `M` выполняет задачи:

- он берёт горутину из локальной очереди своего `P`
    

---

#### Глобальная очередь (Global Run Queue)

Одна на весь runtime.

##### Особенности

- Медленнее (нужен глобальный lock)
    
- Используется как резерв
    
- Без ограничения размера
    

##### Когда используется

- Локальная очередь переполнена
    
- Новый `P` появился
    
- Балансировка нагрузки
    
- Иногда при создании новых горутин
    

---

#### Work Stealing (кража работы)

Если у `P` локальная очередь пустая:

1. Он смотрит в глобальную очередь.
    
2. Если там пусто — **ворует половину задач** у другого `P`.
    

Это ключевой механизм балансировки.

---

#### Зачем две очереди

##### Производительность

Локальные очереди:

- минимум блокировок
    
- высокая скорость
    

##### Балансировка

Глобальная очередь + кража работы:

- равномерная загрузка CPU
    
- нет простаивающих ядер
    

---

#### Упрощённая схема

```
        Global Queue
            |
   -----------------------
   |          |         |
  P1         P2        P3
 [G G G]    [G]       []
   |                     ↑
   |------ steal --------|
```

---

**Суть:**  
Локальная очередь — для скорости.  
Глобальная — для распределения и страховки.  
Work stealing — для баланса нагрузки между ядрами.
### Когда переключаются горутины
Горутины переключаются (происходит **context switch**) когда рантайм Go решает, что текущая горутина **не может или не должна дальше занимать CPU**.

Основные моменты:

---

#### 1. Блокирующие операции (самый частый случай)

Когда горутина не может продолжать работу:

- ожидание канала (`<-ch`, `ch <-`)
    
- `mutex.Lock()` при занятом локе
    
- `time.Sleep`
    
- сетевой I/O
    
- системные вызовы
    
- `select` без готовых кейсов
    

Что происходит:

- горутина → состояние **waiting**
    
- снимается с CPU
    
- планировщик запускает другую
    

---

#### 2. Вытеснение по таймеру (Preemption)

Если горутина слишком долго работает без блокировок:

- рантайм ставит флаг вытеснения
    
- на **safe point** она прерывается
    
- CPU передаётся другой горутине
    

Нужно, чтобы одна задача не “захватила” ядро.

Начиная с Go 1.14 — есть **асинхронное вытеснение** даже в длинных циклах.

---

#### 3. Завершение горутины

Когда функция заканчивается:

- горутина уничтожается
    
- её место занимает следующая из очереди
    

---

#### 4. Создание новых горутин

`go func()` не гарантирует мгновенный switch,  
но часто планировщик сразу ставит новую горутину в очередь и может переключиться.

---

#### 5. Runtime Safe Points

Переключение возможно в точках, где рантайму безопасно сохранить состояние:

- вызовы функций
    
- аллокации памяти
    
- проверки стека
    
- некоторые циклы
    

---

#### Упрощённо

Горутина переключается когда:

- **ждёт ресурс** (I/O, канал, mutex)
    
- **слишком долго работает**
    
- **закончилась**
    
- **runtime решил, что пора**
    

---

##### Ключевая мысль

Переключение в Go происходит **в user-space через рантайм**, а не через ядро ОС, поэтому оно дешёвое и может происходить очень часто без сильных накладных расходов.
### Что такое work stealing - почему его используют, а не work sharing
**Work Stealing** — это стратегия балансировки нагрузки в планировщике, при которой **свободный воркер сам “ворует” задачи у занятых**, а не задачи активно раздаются централизованно.

В Go свободный `P` (processor) берёт половину задач из локальной очереди другого `P`.

---

#### Почему Stealing, а не Sharing

Есть две стратегии:

##### Work Sharing (раздача работы)

**Центральный планировщик раздаёт задачи всем воркерам.**

###### Минусы

- **Глобальный lock / узкое место**
    
- Высокая конкуренция за очередь
    
- Плохая масштабируемость на много ядер
    
- Частые синхронизации
    
- Централизованная точка торможения
    

На 16–32 ядрах начинает сильно деградировать.

---

##### Work Stealing (кража работы)

**Каждый воркер имеет свою локальную очередь.**  
Когда очередь пуста — он сам идёт и ворует задачи у другого.

###### Плюсы

- Нет глобального узкого места
    
- Меньше блокировок
    
- Хорошая масштабируемость
    
- Локальность кэша CPU
    
- Децентрализация
    

---

#### Как это работает в Go

1. У каждого `P` есть локальная очередь.
    
2. `P` выполняет свои задачи.
    
3. Если очередь пуста:
    
    - проверяет глобальную очередь
        
    - если пусто — выбирает случайный `P`
        
    - **крадёт половину его задач**
        

Почему половину:

- чтобы не воровать слишком часто
    
- чтобы не обнулить донора
    

---

#### Почему stealing эффективнее sharing

##### 1. Cache Locality

Задачи остаются на том же ядре → меньше cache miss.

##### 2. Меньше синхронизации

Нет постоянной борьбы за один глобальный mutex.

##### 3. Децентрализация

Нет “главного диспетчера”, который может стать bottleneck.

##### 4. Масштабируемость

Чем больше ядер — тем лучше работает.

##### 5. Ленивость

Балансировка происходит **только когда нужно**, а не постоянно.

---

#### Интуитивная аналогия

**Work Sharing**  
Учитель раздаёт задания каждому ученику → очередь у учителя.

**Work Stealing**  
Ученики работают сами. У кого кончились задания — берёт у соседа.

---

#### Итог

|Критерий|Work Sharing|Work Stealing|
|---|---|---|
|Централизация|Да|Нет|
|Узкое место|Есть|Нет|
|Cache locality|Плохая|Хорошая|
|Масштабируемость|Средняя|Высокая|
|Блокировки|Частые|Редкие|

**Поэтому Go использует Work Stealing:**  
он лучше масштабируется, уменьшает блокировки и эффективнее использует CPU-кэш на многоядерных системах.
### sysmon
**Sysmon (System Monitor) в Go** — это специальная служебная горутина рантайма, которая **следит за состоянием программы и помогает планировщику**.

Это не пользовательская горутина — она запускается самим runtime при старте приложения.

---

#### Задачи sysmon

##### 1. Вытеснение долгих горутин (Preemption)

Если горутина слишком долго занимает CPU:

- sysmon ставит флаг вытеснения
    
- рантайм прерывает её на safe point
    
- другие горутины получают шанс выполниться
    

Нужно для справедливости и отзывчивости.

---

##### 2. Контроль таймеров

Следит за:

- `time.Sleep`
    
- `time.After`
    
- `Ticker`
    
- дедлайнами
    

Когда время наступает — будит нужные горутины.

---

##### 3. Сетевые события (взаимодействие с Netpoller)

Помогает:

- периодически опрашивать сетевые дескрипторы
    
- переводить горутины из `waiting` → `runnable`
    

---

##### 4. Детект блокировок потоков

Если поток ОС завис в системном вызове:

- sysmon может создать новый `M`
    
- чтобы CPU не простаивал
    

---

##### 5. Помощь сборщику мусора (GC)

- триггер GC
    
- координация фаз
    
- safe points
    

---

#### Как работает

- Крутится в фоне
    
- Периодически просыпается (каждые ~10 мс)
    
- Проверяет состояние планировщика, таймеров, потоков, GC
    

Это **фоновый менеджер рантайма**.

---

#### Важно понимать

- Это **одна служебная горутина**
    
- Не исполняет пользовательский код
    
- Не участвует в бизнес-логике
    
- Работает постоянно, пока жив процесс
    

---

##### Короткая суть

**Sysmon — это “смотритель” рантайма Go:  
он следит за таймерами, вытесняет долгие горутины, помогает netpoller и GC и не даёт потокам и задачам зависать.**
### netpoller
**Netpoller в Go** — это часть рантайма, которая отвечает за **неблокирующий сетевой I/O** и пробуждение горутин, ожидающих события сети.

Проще:  
**механизм, который следит за сокетами и будит горутины, когда данные готовы.**

---

#### Зачем нужен netpoller

Без него:

- каждая горутина с `Read/Write` блокировала бы поток ОС
    
- тысячи соединений ⇒ тысячи потоков ⇒ крах по памяти и производительности
    

С netpoller:

- горутина “засыпает”
    
- поток ОС свободен
    
- событие сети будит горутину
    

---

#### Как работает

Go использует системные механизмы ОС:

- Linux — **epoll**
    
- macOS / BSD — **kqueue**
    
- Windows — **IOCP**
    

---

##### Процесс чтения из сокета

1. Горутина вызывает `conn.Read()`.
    
2. Runtime регистрирует сокет в netpoller.
    
3. Если данных нет:
    
    - горутина → `waiting`
        
    - поток ОС освобождается
        
4. ОС сообщает: “сокет готов”.
    
5. Netpoller:
    
    - помечает горутину `runnable`
        
    - кладёт её в очередь планировщика
        
6. Горутина продолжает выполнение.
    

---

#### Что важно

- Поток ОС **не блокируется**.
    
- Горутина **не крутит CPU**.
    
- Один поток может обслуживать **тысячи соединений**.
    

---

#### Связь с планировщиком

Netpoller не выполняет код.  
Он только:

- отслеживает события
    
- переводит горутины из `waiting` → `runnable`
    

Дальше обычный scheduler запускает их на CPU.

---

#### Почему это эффективно

- Нет тысячи OS-потоков
    
- Нет busy-wait
    
- Минимум системных вызовов
    
- Высокая масштабируемость для сетевых сервисов
    

---

##### Короткая суть

**Netpoller — это мост между ОС и горутинами для сетевого I/O:  
он усыпляет горутины, когда данных нет, и будит их, когда сокет готов, не блокируя потоки ОС.**
### Что происходит с горутиной  в тот момент когда она вызывает sys call
Когда горутина делает **syscall (системный вызов)** — происходит важная вещь:

#### Коротко

**Горутина блокируется, поток ОС блокируется, но планировщик Go старается освободить CPU и запустить другие горутины.**

---

#### По шагам

Допустим горутина вызывает `read()` файл или сеть.

##### 1. Горутина входит в syscall

Runtime помечает её состояние как:

```
G -> syscall
```

Она больше не runnable.

---

##### 2. Поток ОС (M) тоже блокируется

Так как syscall — это ядро ОС, поток реально уходит в kernel mode и может ждать:

- диск
    
- сеть
    
- pipe
    
- что угодно
    

Этот `M` теперь **не может выполнять другие горутины**.

---

##### 3. P освобождается

Ключевой момент:

```
M уходит в syscall
P отвязывается от M
```

`P` (процессор планировщика) не простаивает — его может подхватить другой `M`.

---

##### 4. Создаётся/берётся другой поток

Если свободного `M` нет — runtime создаёт новый поток ОС.

И другие горутины продолжают работать.

---

##### 5. Syscall завершился

Когда ядро возвращает управление:

- горутина → `runnable`
    
- поток пытается снова получить `P`
    
- если не получилось — кладёт G в глобальную очередь
    

---

#### Почему это важно

Иначе один `read()` мог бы заморозить всё приложение.

Go изолирует блокировки syscall от всего планировщика.

---

#### Исключение — сетевые операции

Для сети обычно **не делается реальный blocking syscall**:

- используется **netpoller**
    
- epoll/kqueue/iocp
    
- поток не блокируется
    
- горутина просто переводится в `waiting`
    

Поэтому сетевой I/O дешевле, чем файловый.

---

#### Состояния кратко

##### До syscall

```
G = running
M = attached to P
```

##### Во время syscall

```
G = syscall
M = blocked
P = free
```

##### После

```
G = runnable
M пытается получить P
```

---

#### Суть одной строкой

**Syscall блокирует поток ОС, но не блокирует планировщик Go — P освобождается и другие горутины продолжают выполняться.**
# Каналы в Go

### Как устроены каналы (кольцевой буфер, очереди)
Внутри runtime Go канал — это структура данных примерно такого вида:

```
type hchan struct {
    buf      // кольцевой буфер
    sendq    // очередь отправителей
    recvq    // очередь получателей
    lock     // мьютекс
    ...
}
```

---

#### 1. Кольцевой буфер (buffered channel)

Если канал с буфером:

```go
ch := make(chan int, 3)
```

Создаётся **массив фиксированного размера** + два индекса:

- `sendx` — куда писать
    
- `recvx` — откуда читать
    

Работает как **ring buffer**:

```
[ _ _ _ ]
  ^   ^
 recv send
```

- дошли до конца → переход в начало
    
- O(1) вставка и чтение
    

Если буфер:

- **полон** → отправитель блокируется
    
- **пуст** → получатель блокируется
    

---

#### 2. Очереди горутин

Когда буфер не помогает — используются очереди.

##### sendq — очередь отправителей

Туда кладутся горутины, если:

- буфер полный
    
- нет получателя
    

##### recvq — очередь получателей

Туда кладутся горутины, если:

- буфер пуст
    
- нет отправителя
    

Это **FIFO списки goroutine descriptors** (sudog).

---

#### 3. Unbuffered канал

Буфера нет вообще.

```
send <-> recv
```

Работает как **рукопожатие**:

- отправитель ищет получателя в `recvq`
    
- если есть — данные копируются напрямую
    
- если нет — отправитель засыпает в `sendq`
    

---

#### 4. Lock

Каждая операция канала берёт **мьютекс**:

- защита буфера
    
- защита очередей
    
- атомарность
    

Поэтому каналы потокобезопасны.

---

#### Что происходит при send

1. Lock
    
2. Есть recv в очереди? → прямой копипаст
    
3. Есть место в буфере? → запись в ring
    
4. Иначе → горутина в `sendq` и sleep
    
5. Unlock
    

---

#### Что происходит при recv

Зеркально send:

1. Lock
    
2. Есть send в очереди? → прямой копипаст
    
3. Буфер не пуст? → чтение
    
4. Иначе → в `recvq` и sleep
    
5. Unlock
    

---

#### Короткая суть

Канал в Go =

- **Ring buffer** (если buffered)
    
- **2 FIFO очереди горутин** (send/recv)
    
- **Мьютекс**
    
- **Прямое копирование данных между горутинами**, если возможно.
    

Это не просто очередь значений — это ещё и **очередь ожидающих горутин**.
### буферизированные и небуферизированные каналы
### Паттерны использования каналов (pipe, fan in, fan out)
Коротко — это **типовые схемы передачи данных через каналы**.

---

#### 1. Pipe (Pipeline, конвейер)

Последовательная обработка этапами.

```
G1 -> ch1 -> G2 -> ch2 -> G3
```

Пример:

- чтение файла → парсинг → запись в БД
    

Каждый этап — отдельная горутина.

**Плюсы:**  
простая композиция, потоковая обработка.

---

#### 2. Fan-Out (распараллеливание)

Один источник → много воркеров.

```
        -> G2
G1 -> ch -> G3
        -> G4
```

Используется для CPU-тяжёлых задач:

- хеширование
    
- обработка изображений
    
- расчёты
    

**Идея:** несколько горутин читают из одного канала.

---

#### 3. Fan-In (сбор результатов)

Много источников → один получатель.

```
G1 ->
G2 -> ch -> G4
G3 ->
```

Используется для:

- агрегации результатов
    
- логирования
    
- метрик
    

Обычно делается через `select` или merge-горутины.

---

##### Суть в одном абзаце

- **Pipe** — этапы последовательно.
    
- **Fan-Out** — один вход, много исполнителей.
    
- **Fan-In** — много источников, один сборщик.
    

Это базовые строительные блоки конкурентных пайплайнов в Go.
### невалидные операции с каналами 
![[Pasted image 20260112121855.png]]


## Память и GC в Go

### Стек горитин - размер, рост, contiguos stack, segmented stack, где стек горутин находится
#### Стек горутины в Go

##### Где находится

Стек горутины лежит **в куче (heap)** процесса, а не в стеке потока ОС.

Поэтому его можно:

- перемещать
    
- увеличивать
    
- уменьшать
    

---

#### Начальный размер

Очень маленький:

**~2 КБ** (раньше было 4–8 КБ).

Это позволяет создавать сотни тысяч горутин.

---

#### Рост стека

Стек **динамический**:

- при переполнении → увеличивается
    
- при сильном уменьшении использования → может сжиматься
    

Рост обычно **в 2 раза**.

---

#### Contiguous Stack (текущая модель)

Сейчас Go использует **непрерывный стек**.

##### Как растёт

1. Выделяется новый участок памяти большего размера
    
2. Старый стек копируется туда
    
3. Указатели обновляются
    

Плюсы:

- быстрый доступ к памяти
    
- хорошая локальность кэша
    
- меньше накладных расходов
    

Минус:

- копирование при росте
    

---

#### Segmented Stack (старая модель, до Go 1.3)

Раньше стек был **сегментированным**:

```
[seg1] -> [seg2] -> [seg3]
```

Проблемы:

- много аллокаций
    
- плохая локальность кэша
    
- overhead на переходы между сегментами
    
- stack thrashing (частые переключения сегментов)
    

Поэтому отказались.

---

#### Размер стека

Теоретически — до гигабайтов,  
на практике — **несколько МБ максимум**.

Обычно:

- 2 КБ старт
    
- десятки/сотни КБ в реальных задачах
    

---

#### Отличие от стека потока ОС

Стек потока ОС:

- фиксированный размер (1–8 МБ)
    
- выделяется сразу
    
- не растёт
    

Стек горутины:

- маленький старт
    
- динамический рост
    
- в heap
    
- переносимый
    

---

##### Короткая суть

**Стек горутины — маленький (≈2 КБ), лежит в heap, растёт динамически, сейчас непрерывный (contiguous), раньше был сегментированный (segmented).**
### Аллокатор го - как выделяет память
### Сборщик мусора - как работает, как устроен, какие есть фазы, по какой модели работает, колгде полностью отстаналивается программа
### Как можно управлять сборщиком мусора
